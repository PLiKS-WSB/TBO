{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUKA-2jB9cwx",
        "outputId": "a5e68905-9a1c-489f-d24c-bb89d06274fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.12/dist-packages (3.2.9)\n"
          ]
        }
      ],
      "source": [
        "%pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUoTVEOF7ZYV"
      },
      "source": [
        "###Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM8xdGJQ8fPX",
        "outputId": "c81f19de-e9b5-4f51-822a-97639f61c42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Part A — Required Hours per Subspecialism (Backlog-inclusive OPD; Surgeries in 1040–3120) ===\n",
            " subspec  OPD hours  OR hours  Ward hours  Admin hours\n",
            "       1     780.50    120.17       63.85       280.58\n",
            "       2     228.42     94.83       54.20       218.00\n",
            "       3     108.10    118.00       28.55        92.75\n",
            "       4     754.83    191.50       82.45       243.75\n",
            "       5     302.83     50.17       28.40       137.00\n",
            "       6     277.00     50.50       25.10       144.17\n",
            "       7     206.20     24.50        8.50        83.33\n",
            "       8     136.60     43.17       25.85       105.42\n",
            "       9     254.92     38.00       17.75       161.83\n",
            "      10     343.47     43.17       20.00       121.33\n",
            "\n",
            "=== Part A — Total Required Hours (All Tasks) ===\n",
            "                           Total hours\n",
            "Task                                  \n",
            "Ward hours                      354.65\n",
            "Outpatient (OPD) hours        3,392.87\n",
            "Operating Room (OR) hours       774.00\n",
            "Administration hours          1,588.17\n",
            "Education hours               1,200.00\n",
            "Conferences hours             1,560.00\n",
            "\n",
            "Detected number of specialists (N) = 15\n",
            "\n",
            "Assumptions used:\n",
            "- OPD: BACKLOG-INCLUSIVE → all first-visit arrivals with arrival(h) ≤ 3120 are counted.\n",
            "- Surgeries: only those with due-date op(h) in [1040, 3120] (from Surgery Queue).\n",
            "- Ward: 15 min × (LOS+1) weekday-only;\n",
            "    * Initial in-ward (t=1040): exact Mon–Fri count (simulation starts Monday).\n",
            "    * Post-op: average Mon–Fri count over Mon–Fri surgery starts.\n",
            "- Admin: 5 min per OPD first visit (backlog-inclusive) + 10 min per surgery (in-window).\n",
            "- Education: 80 h × N specialists; Conferences: 104 h × N specialists.\n",
            "- No emergency patients; unlimited beds; predetermined OR durations & LOS; no return OPD visits.\n",
            "\n",
            "Saved results to: PartA_required_hours_BACKLOG.xlsx\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Assignment 7 - Part A (Backlog-inclusive OPD)\n",
        "# Total Capacity Planning with Weekday-Aware Ward\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Settings ---\n",
        "DATA_PATH = \"Data for Assignment 7.xlsx\"   # Upload this Excel to Colab working dir\n",
        "START_H, END_H = 1040, 3120                # Planning window (inclusive)\n",
        "SAVE_EXCEL = True                          # Save outputs to an .xlsx file\n",
        "# We will use a precise weekday-aware method (no 5/7 heuristic):\n",
        "# - Initial in-ward: exact weekday count (simulation starts Monday)\n",
        "# - Post-op: average weekday count over Mon–Fri start days\n",
        "\n",
        "# --- Load sheets ---\n",
        "xls = pd.ExcelFile(DATA_PATH)\n",
        "patients   = pd.read_excel(xls, \"Patients\")\n",
        "squeue     = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward    = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los   = pd.read_excel(xls, \"surgeryLOS\")\n",
        "specialist = pd.read_excel(xls, \"specialist\")\n",
        "\n",
        "# --- Clean / coerce types ---\n",
        "patients['arrival (h)']   = pd.to_numeric(patients['arrival (h)'], errors='coerce')\n",
        "patients['timeod (min)']  = pd.to_numeric(patients['timeod (min)'], errors='coerce')\n",
        "patients['subspec']       = pd.to_numeric(patients['subspec'], errors='coerce')\n",
        "patients['subsubsp']      = pd.to_numeric(patients['subsubsp'], errors='coerce')\n",
        "\n",
        "squeue['subspec']         = pd.to_numeric(squeue['subspec'], errors='coerce')\n",
        "squeue['subsubsp']        = pd.to_numeric(squeue['subsubsp'], errors='coerce')\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "\n",
        "surg_los = surg_los.rename(columns={'subsub': 'subsubsp'})\n",
        "surg_los['subspec']             = pd.to_numeric(surg_los['subspec'], errors='coerce')\n",
        "surg_los['subsubsp']            = pd.to_numeric(surg_los['subsubsp'], errors='coerce')\n",
        "surg_los['surgery time(min)']   = pd.to_numeric(surg_los['surgery time(min)'], errors='coerce')\n",
        "surg_los['LOS(DAYS)']           = pd.to_numeric(surg_los['LOS(DAYS)'], errors='coerce')\n",
        "\n",
        "in_ward['subspec']        = pd.to_numeric(in_ward['subspec'], errors='coerce')\n",
        "in_ward['remaining LOS']  = pd.to_numeric(in_ward['remaining LOS'], errors='coerce')\n",
        "\n",
        "# --- Detect N specialists from 'specialist' sheet ---\n",
        "def detect_N(df):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    # Many datasets put specialist IDs (1..15) across columns in row 0\n",
        "    header_nums = pd.to_numeric(df.iloc[0, 2:], errors='coerce')\n",
        "    n = int(header_nums.notna().sum())\n",
        "    if n == 0 and 'specialist' in df.columns:\n",
        "        fte_row = df[df['specialist'].astype(str).str.upper().eq('FTE')]\n",
        "        if not fte_row.empty:\n",
        "            fte_nums = pd.to_numeric(fte_row.iloc[0, 2:], errors='coerce')\n",
        "            n = int(fte_nums.notna().sum())\n",
        "    return n if n > 0 else None\n",
        "\n",
        "N = detect_N(specialist) or 15  # fallback if structure is different\n",
        "\n",
        "# --- Helper functions for weekday-aware ward counting ---\n",
        "# weekday indices: 0=Mon, 1=Tue, 2=Wed, 3=Thu, 4=Fri, 5=Sat, 6=Sun\n",
        "\n",
        "def count_weekdays_in_span(start_weekday: int, length_days: int) -> int:\n",
        "    \"\"\"Exact number of weekdays (Mon–Fri) in a consecutive span starting on start_weekday.\"\"\"\n",
        "    if length_days <= 0:\n",
        "        return 0\n",
        "    full_weeks, rem = divmod(length_days, 7)\n",
        "    base = full_weeks * 5\n",
        "    cnt = 0\n",
        "    for i in range(rem):\n",
        "        wd = (start_weekday + i) % 7\n",
        "        if wd < 5:  # Mon–Fri\n",
        "            cnt += 1\n",
        "    return base + cnt\n",
        "\n",
        "def avg_weekdays_over_weekday_starts(length_days: int) -> float:\n",
        "    \"\"\"Average weekday count when the span starts on an unknown weekday (Mon–Fri equally likely).\"\"\"\n",
        "    if length_days <= 0:\n",
        "        return 0.0\n",
        "    vals = [count_weekdays_in_span(start_wd, length_days) for start_wd in range(5)]  # Mon..Fri\n",
        "    return sum(vals) / 5.0\n",
        "\n",
        "# --- Apply planning rules ---\n",
        "\n",
        "# OPD (BACKLOG-INCLUSIVE):\n",
        "#   Count any patient whose first-visit arrival happens on/before the end of the year.\n",
        "#   (This includes those already waiting at t=1040 as well as new arrivals.)\n",
        "opd_year = patients[patients['arrival (h)'] <= END_H].copy()\n",
        "opd_by_sub_min = opd_year.groupby('subspec', dropna=True)['timeod (min)'].sum().rename('OPD minutes').reset_index()\n",
        "\n",
        "# Surgeries due within the planning window (strict in-window by due date)\n",
        "map_cols  = ['subspec', 'subsubsp', 'surgery time(min)', 'LOS(DAYS)']\n",
        "surg_map  = surg_los[map_cols].drop_duplicates()\n",
        "surg_year = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_m    = surg_year.merge(surg_map, on=['subspec', 'subsubsp'], how='left')\n",
        "\n",
        "# OR minutes per subspecialism\n",
        "or_by_sub_min = (\n",
        "    surg_m.groupby('subspec', dropna=True)['surgery time(min)']\n",
        "          .sum(min_count=1).fillna(0)\n",
        "          .rename('OR minutes').reset_index()\n",
        ")\n",
        "\n",
        "# Ward minutes:\n",
        "#   Initial in-ward at t=1040 → exact weekdays (simulation starts Monday)\n",
        "SIM_START_WEEKDAY = 0  # Monday\n",
        "in_ward = in_ward.copy()\n",
        "in_ward['remaining LOS'] = in_ward['remaining LOS'].fillna(0).astype(int)\n",
        "in_ward['ward_days_initial'] = in_ward['remaining LOS'] + 1\n",
        "in_ward['weekday_visits_initial'] = in_ward['ward_days_initial'].apply(\n",
        "    lambda k: count_weekdays_in_span(SIM_START_WEEKDAY, k)\n",
        ")\n",
        "in_ward['Ward minutes (initial)'] = 15 * in_ward['weekday_visits_initial']\n",
        "ward_init_by_sub_min = (\n",
        "    in_ward.groupby('subspec', dropna=True)['Ward minutes (initial)']\n",
        "           .sum().reset_index()\n",
        ")\n",
        "\n",
        "#   Post-op from surgeries in window → average weekdays over weekday starts\n",
        "surg_m = surg_m.copy()\n",
        "surg_m['LOS(DAYS)'] = surg_m['LOS(DAYS)'].fillna(0).astype(int)\n",
        "surg_m['ward_days_postop'] = surg_m['LOS(DAYS)'] + 1\n",
        "surg_m['weekday_visits_postop'] = surg_m['ward_days_postop'].apply(avg_weekdays_over_weekday_starts)\n",
        "surg_m['Ward minutes (post-op)'] = 15 * surg_m['weekday_visits_postop']\n",
        "ward_postop_by_sub_min = (\n",
        "    surg_m.groupby('subspec', dropna=True)['Ward minutes (post-op)']\n",
        "          .sum().reset_index()\n",
        ")\n",
        "\n",
        "# Administration minutes per subspecialism (windowed counts)\n",
        "opd_counts  = opd_year.groupby('subspec', dropna=True).size().rename('OPD count').reset_index()\n",
        "surg_counts = surg_m.groupby('subspec', dropna=True).size().rename('Surgery count').reset_index()\n",
        "admin_opd_by_sub  = opd_counts.assign(admin_minutes_opd  = lambda d: d['OPD count'] * 5)[['subspec','admin_minutes_opd']]\n",
        "admin_surg_by_sub = surg_counts.assign(admin_minutes_surg = lambda d: d['Surgery count'] * 10)[['subspec','admin_minutes_surg']]\n",
        "\n",
        "# --- Merge per-subspecialism and convert to HOURS ---\n",
        "from functools import reduce\n",
        "dfs = [\n",
        "    opd_by_sub_min,\n",
        "    or_by_sub_min,\n",
        "    ward_postop_by_sub_min,\n",
        "    ward_init_by_sub_min,\n",
        "    admin_opd_by_sub,\n",
        "    admin_surg_by_sub\n",
        "]\n",
        "per_sub = reduce(lambda L, R: L.merge(R, on='subspec', how='outer'), dfs).fillna(0)\n",
        "\n",
        "per_sub['OPD hours']   = per_sub['OPD minutes'] / 60.0\n",
        "per_sub['OR hours']    = per_sub['OR minutes'] / 60.0\n",
        "per_sub['Ward hours']  = (per_sub['Ward minutes (post-op)'] + per_sub['Ward minutes (initial)']) / 60.0\n",
        "per_sub['Admin hours'] = (per_sub['admin_minutes_opd'] + per_sub['admin_minutes_surg']) / 60.0\n",
        "\n",
        "per_sub_table = (\n",
        "    per_sub[['subspec','OPD hours','OR hours','Ward hours','Admin hours']]\n",
        "    .sort_values('subspec')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# --- Totals (first 4 tasks + fixed tasks) ---\n",
        "totals = {\n",
        "    'Ward hours':                float(per_sub_table['Ward hours'].sum()),\n",
        "    'Outpatient (OPD) hours':    float(per_sub_table['OPD hours'].sum()),\n",
        "    'Operating Room (OR) hours': float(per_sub_table['OR hours'].sum()),\n",
        "    'Administration hours':      float(per_sub_table['Admin hours'].sum()),\n",
        "    'Education hours':           float(N * 80),\n",
        "    'Conferences hours':         float(N * (2*40 + 24)),  # 104 per specialist\n",
        "}\n",
        "totals_df = pd.DataFrame(list(totals.items()), columns=['Task','Total hours']).set_index('Task')\n",
        "\n",
        "# --- Print results ---\n",
        "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
        "print(\"\\n=== Part A — Required Hours per Subspecialism (Backlog-inclusive OPD; Surgeries in 1040–3120) ===\")\n",
        "print(per_sub_table.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== Part A — Total Required Hours (All Tasks) ===\")\n",
        "print(totals_df.to_string())\n",
        "\n",
        "print(f\"\\nDetected number of specialists (N) = {N}\")\n",
        "print(\"\\nAssumptions used:\")\n",
        "print(\"- OPD: BACKLOG-INCLUSIVE → all first-visit arrivals with arrival(h) ≤ 3120 are counted.\")\n",
        "print(\"- Surgeries: only those with due-date op(h) in [1040, 3120] (from Surgery Queue).\")\n",
        "print(\"- Ward: 15 min × (LOS+1) weekday-only;\")\n",
        "print(\"    * Initial in-ward (t=1040): exact Mon–Fri count (simulation starts Monday).\")\n",
        "print(\"    * Post-op: average Mon–Fri count over Mon–Fri surgery starts.\")\n",
        "print(\"- Admin: 5 min per OPD first visit (backlog-inclusive) + 10 min per surgery (in-window).\")\n",
        "print(\"- Education: 80 h × N specialists; Conferences: 104 h × N specialists.\")\n",
        "print(\"- No emergency patients; unlimited beds; predetermined OR durations & LOS; no return OPD visits.\")\n",
        "\n",
        "# --- Save to Excel (optional) ---\n",
        "if SAVE_EXCEL:\n",
        "    out_path = \"PartA_required_hours_BACKLOG.xlsx\"\n",
        "    with pd.ExcelWriter(out_path, engine=\"xlsxwriter\") as writer:\n",
        "        per_sub_table.to_excel(writer, sheet_name=\"Per Subspecialism\", index=False)\n",
        "        totals_df.reset_index().to_excel(writer, sheet_name=\"Totals\", index=False)\n",
        "    print(f\"\\nSaved results to: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_DCsJoe7cig"
      },
      "source": [
        "###Part B\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part B — Corrected LP: minimize total specialist capacity (hours)\n",
        "# - Enforces mandatory education/conference/holiday hours per specialist\n",
        "# - Uses explicit, robust parsing of 'specialist' sheet (spec_id, fte, skills)\n",
        "# - If 'specialist' sheet missing clean format, falls back to ALL-SKILLED (with warning)\n",
        "# - Prints results inline (no files saved)\n",
        "#\n",
        "# Requirements: pandas, numpy, scipy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from scipy.optimize import linprog\n",
        "import math\n",
        "\n",
        "# ---------- Settings ----------\n",
        "DATA_PATH = \"Data for Assignment 7.xlsx\"   # ensure uploaded\n",
        "START_H, END_H = 1040, 3120\n",
        "SIM_START_WEEKDAY = 0  # Monday\n",
        "HOURS_PER_YEAR = 52 * 40  # 2080\n",
        "\n",
        "# mandatory defaults (can be overridden per-specialist in 'specialist' sheet)\n",
        "DEFAULT_EDUCATION_H = 80.0\n",
        "DEFAULT_CONFERENCE_H = 104.0\n",
        "DEFAULT_HOLIDAY_H = 0.0  # include if you want a fixed holiday allowance\n",
        "\n",
        "# ---------- weekday helper (Part A ward calculations) ----------\n",
        "def count_weekdays_in_span(start_weekday: int, length_days: int) -> int:\n",
        "    if length_days <= 0: return 0\n",
        "    full_weeks, rem = divmod(length_days, 7)\n",
        "    base = full_weeks * 5\n",
        "    cnt = sum(1 for i in range(rem) if (start_weekday + i) % 7 < 5)\n",
        "    return base + cnt\n",
        "\n",
        "def avg_weekdays_over_weekday_starts(length_days: int) -> float:\n",
        "    if length_days <= 0: return 0.0\n",
        "    vals = [count_weekdays_in_span(wd, length_days) for wd in range(5)]\n",
        "    return np.mean(vals)\n",
        "\n",
        "# ---------- Load data ----------\n",
        "xls = pd.ExcelFile(DATA_PATH)\n",
        "patients   = pd.read_excel(xls, \"Patients\")\n",
        "squeue     = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward    = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los   = pd.read_excel(xls, \"surgeryLOS\")\n",
        "spec_sheet = pd.read_excel(xls, \"specialist\")\n",
        "\n",
        "# ---------- Coerce numeric where expected ----------\n",
        "patients['arrival (h)'] = pd.to_numeric(patients['arrival (h)'], errors='coerce')\n",
        "patients['timeod (min)'] = pd.to_numeric(patients['timeod (min)'], errors='coerce')\n",
        "patients['subspec'] = pd.to_numeric(patients['subspec'], errors='coerce')\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "\n",
        "surg_los = surg_los.rename(columns={'subsub': 'subsubsp'})\n",
        "surg_los['subspec'] = pd.to_numeric(surg_los['subspec'], errors='coerce')\n",
        "surg_los['subsubsp'] = pd.to_numeric(surg_los['subsubsp'], errors='coerce')\n",
        "surg_los['surgery time(min)'] = pd.to_numeric(surg_los['surgery time(min)'], errors='coerce')\n",
        "surg_los['LOS(DAYS)'] = pd.to_numeric(surg_los['LOS(DAYS)'], errors='coerce')\n",
        "\n",
        "in_ward['subspec'] = pd.to_numeric(in_ward['subspec'], errors='coerce')\n",
        "in_ward['remaining LOS'] = pd.to_numeric(in_ward['remaining LOS'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# ---------- Reproduce Part A: required hours per subspecialism × task ----------\n",
        "# OPD (backlog-inclusive)\n",
        "opd_year = patients[patients['arrival (h)'] <= END_H].copy()\n",
        "opd_by_sub_min = opd_year.groupby('subspec', dropna=True)['timeod (min)'].sum().rename('OPD minutes').reset_index()\n",
        "\n",
        "# Surgeries in-window and mapping\n",
        "map_cols  = ['subspec','subsubsp','surgery time(min)','LOS(DAYS)']\n",
        "surg_map = surg_los[map_cols].drop_duplicates()\n",
        "surg_year = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_m = surg_year.merge(surg_map, on=['subspec','subsubsp'], how='left')\n",
        "\n",
        "or_by_sub_min = surg_m.groupby('subspec', dropna=True)['surgery time(min)'].sum(min_count=1).fillna(0).rename('OR minutes').reset_index()\n",
        "\n",
        "# Ward initial\n",
        "in_ward['ward_days_initial'] = in_ward['remaining LOS'] + 1\n",
        "in_ward['weekday_visits_initial'] = in_ward['ward_days_initial'].apply(lambda k: count_weekdays_in_span(SIM_START_WEEKDAY, k))\n",
        "in_ward['Ward minutes (initial)'] = 15 * in_ward['weekday_visits_initial']\n",
        "ward_init_by_sub_min = in_ward.groupby('subspec', dropna=True)['Ward minutes (initial)'].sum().reset_index()\n",
        "\n",
        "# Ward post-op\n",
        "surg_m['LOS(DAYS)'] = surg_m['LOS(DAYS)'].fillna(0).astype(int)\n",
        "surg_m['ward_days_postop'] = surg_m['LOS(DAYS)'] + 1\n",
        "surg_m['weekday_visits_postop'] = surg_m['ward_days_postop'].apply(avg_weekdays_over_weekday_starts)\n",
        "surg_m['Ward minutes (post-op)'] = 15 * surg_m['weekday_visits_postop']\n",
        "ward_post_by_sub_min = surg_m.groupby('subspec', dropna=True)['Ward minutes (post-op)'].sum().reset_index()\n",
        "\n",
        "# Admin\n",
        "opd_counts = opd_year.groupby('subspec', dropna=True).size().rename('OPD count').reset_index()\n",
        "surg_counts = surg_m.groupby('subspec', dropna=True).size().rename('Surgery count').reset_index()\n",
        "admin_opd_by_sub = opd_counts.assign(admin_minutes_opd = lambda d: d['OPD count'] * 5)[['subspec','admin_minutes_opd']]\n",
        "admin_surg_by_sub = surg_counts.assign(admin_minutes_surg = lambda d: d['Surgery count'] * 10)[['subspec','admin_minutes_surg']]\n",
        "\n",
        "dfs = [opd_by_sub_min, or_by_sub_min, ward_post_by_sub_min, ward_init_by_sub_min, admin_opd_by_sub, admin_surg_by_sub]\n",
        "per_sub = reduce(lambda L,R: L.merge(R, on='subspec', how='outer'), dfs).fillna(0)\n",
        "\n",
        "per_sub['OPD hours'] = per_sub['OPD minutes'] / 60.0\n",
        "per_sub['OR hours'] = per_sub['OR minutes'] / 60.0\n",
        "per_sub['Ward hours'] = (per_sub['Ward minutes (post-op)'] + per_sub['Ward minutes (initial)']) / 60.0\n",
        "per_sub['Admin hours'] = (per_sub['admin_minutes_opd'] + per_sub['admin_minutes_surg']) / 60.0\n",
        "\n",
        "per_sub_table = per_sub[['subspec','OPD hours','OR hours','Ward hours','Admin hours']].sort_values('subspec').reset_index(drop=True)\n",
        "\n",
        "# canonical subspecialism list\n",
        "subspecs = sorted(per_sub_table['subspec'].dropna().astype(int).unique().tolist())\n",
        "if len(subspecs) == 0:\n",
        "    raise RuntimeError(\"No subspecialisms detected in Part A output.\")\n",
        "\n",
        "task_types = ['OPD','OR','Ward','Admin']\n",
        "task_list = [(s,t) for s in subspecs for t in task_types]\n",
        "num_tasks = len(task_list)\n",
        "\n",
        "# required hours vector R_j\n",
        "req_hours = []\n",
        "for s in subspecs:\n",
        "    row = per_sub_table[per_sub_table['subspec']==s]\n",
        "    if row.empty:\n",
        "        vals = [0.0,0.0,0.0,0.0]\n",
        "    else:\n",
        "        vals = [float(row['OPD hours'].iloc[0]), float(row['OR hours'].iloc[0]),\n",
        "                float(row['Ward hours'].iloc[0]), float(row['Admin hours'].iloc[0])]\n",
        "    req_hours.extend(vals)\n",
        "req_hours = np.array(req_hours, dtype=float)\n",
        "\n",
        "# ---------- Specialist sheet parsing (explicit format expected) ----------\n",
        "# Expected format (recommended):\n",
        "# Columns: spec_id, fte (optional), skills (optional, comma-separated subspec ids),\n",
        "# optional columns: education_h, conference_h, holiday_h\n",
        "#\n",
        "# Example row:\n",
        "# spec_id | fte | skills     | education_h | conference_h | holiday_h\n",
        "# S1      | 1.0 | 1,2,3,5    | 80          | 104          | 0\n",
        "\n",
        "spec_df = spec_sheet.copy()\n",
        "\n",
        "# Normalise column names\n",
        "spec_df.columns = [str(c).strip() for c in spec_df.columns]\n",
        "\n",
        "has_spec_id = any('spec' in str(c).lower() for c in spec_df.columns)\n",
        "if has_spec_id and 'skills' in [c.lower() for c in spec_df.columns]:\n",
        "    # robust parsing path: use spec_id, fte (if present), skills\n",
        "    # find spec_id column\n",
        "    spec_id_col = next(c for c in spec_df.columns if 'spec' in c.lower())\n",
        "    fte_col = next((c for c in spec_df.columns if 'fte' in c.lower()), None)\n",
        "    skills_col = next(c for c in spec_df.columns if c.lower() == 'skills' or 'skill' in c.lower())\n",
        "\n",
        "    spec_ids = spec_df[spec_id_col].astype(str).fillna('').tolist()\n",
        "    ftes = spec_df[fte_col].astype(float).fillna(1.0).tolist() if fte_col else [1.0]*len(spec_ids)\n",
        "\n",
        "    edu_col = next((c for c in spec_df.columns if 'educ' in c.lower()), None)\n",
        "    conf_col = next((c for c in spec_df.columns if 'conf' in c.lower()), None)\n",
        "    hol_col = next((c for c in spec_df.columns if 'hol' in c.lower()), None)\n",
        "\n",
        "    education_h = spec_df[edu_col].astype(float).fillna(DEFAULT_EDUCATION_H).tolist() if edu_col else [DEFAULT_EDUCATION_H]*len(spec_ids)\n",
        "    conference_h = spec_df[conf_col].astype(float).fillna(DEFAULT_CONFERENCE_H).tolist() if conf_col else [DEFAULT_CONFERENCE_H]*len(spec_ids)\n",
        "    holiday_h = spec_df[hol_col].astype(float).fillna(DEFAULT_HOLIDAY_H).tolist() if hol_col else [DEFAULT_HOLIDAY_H]*len(spec_ids)\n",
        "\n",
        "    skills_list = []\n",
        "    for val in spec_df[skills_col].fillna(''):\n",
        "        if str(val).strip()=='':\n",
        "            skills_list.append(set())  # empty set\n",
        "        else:\n",
        "            # parse comma-separated ints\n",
        "            toks = [t.strip() for t in str(val).split(',') if t.strip()!='']\n",
        "            ints = []\n",
        "            for t in toks:\n",
        "                try:\n",
        "                    ints.append(int(float(t)))\n",
        "                except:\n",
        "                    pass\n",
        "            skills_list.append(set(ints))\n",
        "\n",
        "    # Build arrays\n",
        "    num_specs = len(spec_ids)\n",
        "    ftes = np.array(ftes, dtype=float)\n",
        "    avail_hours = (HOURS_PER_YEAR * ftes).astype(float)\n",
        "    mandatory_hours = np.array([education_h[i] + conference_h[i] + holiday_h[i] for i in range(num_specs)], dtype=float)\n",
        "    skills = skills_list\n",
        "\n",
        "    parsed_clean = True\n",
        "else:\n",
        "    # Fallback: warn and assume ALL specialists are equally available and all-skilled\n",
        "    print(\"Warning: 'specialist' sheet not in expected clean format (spec_id + skills).\")\n",
        "    print(\"Falling back to conservative assumption: 12 full-time all-skilled specialists.\")\n",
        "    num_specs = 12\n",
        "    spec_ids = [f\"S{i+1}\" for i in range(num_specs)]\n",
        "    ftes = np.array([1.0]*num_specs)\n",
        "    avail_hours = np.array([HOURS_PER_YEAR]*num_specs, dtype=float)\n",
        "    mandatory_hours = np.array([DEFAULT_EDUCATION_H + DEFAULT_CONFERENCE_H + DEFAULT_HOLIDAY_H]*num_specs, dtype=float)\n",
        "    skills = [set(subspecs) for _ in range(num_specs)]\n",
        "    parsed_clean = False\n",
        "\n",
        "# ---------- Build skill matrix (num_specs x num_tasks) ----------\n",
        "skill_matrix = np.zeros((num_specs, num_tasks), dtype=int)\n",
        "for i in range(num_specs):\n",
        "    for j, (s,t) in enumerate(task_list):\n",
        "        if s in skills[i]:\n",
        "            skill_matrix[i,j] = 1\n",
        "        else:\n",
        "            skill_matrix[i,j] = 0\n",
        "\n",
        "# Quick feasibility diagnostic (could show impossible tasks)\n",
        "potential_per_task = np.zeros(num_tasks, dtype=float)\n",
        "for j in range(num_tasks):\n",
        "    idxs = [i for i in range(num_specs) if skill_matrix[i,j]==1]\n",
        "    potential_per_task[j] = sum(avail_hours[i] - mandatory_hours[i] for i in idxs) if len(idxs)>0 else 0.0\n",
        "\n",
        "diag = []\n",
        "for j,(s,t) in enumerate(task_list):\n",
        "    diag.append({\n",
        "        'subspec': s, 'task': t,\n",
        "        'required_h': req_hours[j],\n",
        "        'potential_capacity_from_skilled_specs': potential_per_task[j],\n",
        "        'feasible_by_skill': potential_per_task[j] + 1e-9 >= req_hours[j]\n",
        "    })\n",
        "diag_df = pd.DataFrame(diag)\n",
        "\n",
        "# ---------- Build LP (variables: X_{i,j} for tasks, C_i for capacity provided) ----------\n",
        "# Variable ordering: first all X (num_specs * num_tasks), then all C (num_specs)\n",
        "n_x = num_specs * num_tasks\n",
        "n_c = num_specs\n",
        "n_vars = n_x + n_c\n",
        "\n",
        "# Objective: minimize sum_i C_i  (total capacity hours used)\n",
        "c = np.concatenate([np.zeros(n_x), np.ones(n_c)])  # zeros for X; ones for C\n",
        "\n",
        "# Bounds:\n",
        "# - For X_{i,j}: if skill_matrix==1 -> (0, avail_hours[i] - mandatory_hours[i]) else (0,0)\n",
        "#   (we don't allow X to exceed available after mandatory)\n",
        "# - For C_i: (0, avail_hours[i])\n",
        "bounds = []\n",
        "for i in range(num_specs):\n",
        "    max_assignable = max(0.0, avail_hours[i] - mandatory_hours[i])\n",
        "    for j in range(num_tasks):\n",
        "        if skill_matrix[i,j]==1:\n",
        "            bounds.append((0.0, max_assignable))\n",
        "        else:\n",
        "            bounds.append((0.0, 0.0))\n",
        "# bounds for C_i\n",
        "for i in range(num_specs):\n",
        "    bounds.append((0.0, float(avail_hours[i])))\n",
        "\n",   d
        "# Constraints as A_ub x <= b_ub\n",
        "A_ub = []\n",
        "b_ub = []\n",
        "\n",
        "# 1) Task coverage: -sum_i X_ij <= -R_j  (for each task j)\n",
        "for j in range(num_tasks):\n",
        "    row = np.zeros(n_vars)\n",
        "    for i in range(num_specs):\n",
        "        var_idx = i * num_tasks + j\n",
        "        row[var_idx] = -1.0\n",
        "    A_ub.append(row)\n",
        "    b_ub.append(-req_hours[j])\n",
        "\n",
        "# 2) Per-specialist: sum_j X_ij - C_i <= -mandatory_hours[i]\n",
        "#    (i.e., sum_assignments + mandatory <= C_i  =>  sum_assignments - C_i <= -mandatory)\n",
        "for i in range(num_specs):\n",
        "    row = np.zeros(n_vars)\n",
        "    # X variables for specialist i\n",
        "    for j in range(num_tasks):\n",
        "        row[i * num_tasks + j] = 1.0\n",
        "    # C_i variable index\n",
        "    c_idx = n_x + i\n",
        "    row[c_idx] = -1.0\n",
        "    A_ub.append(row)\n",
        "    b_ub.append(-mandatory_hours[i])\n",
        "\n",
        "# 3) (optionally redundant) C_i <= avail_hours[i] already enforced by bounds; no need to add.\n",
        "\n",
        "A_ub = np.vstack(A_ub)\n",
        "b_ub = np.array(b_ub, dtype=float)\n",
        "\n",
        "# ---------- Solve LP ----------\n",
        "print(\"Solving corrected LP (minimize total capacity used)...\")\n",
        "res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n",
        "\n",
        "if not res.success:\n",
        "    print(\"LP failed/infeasible:\", res.message)\n",
        "    print(\"\\nFeasibility diagnostics for tasks (showing tasks that cannot be covered by skilled capacity):\")\n",
        "    print(diag_df[~diag_df['feasible_by_skill']].to_string(index=False))\n",
        "else:\n",
        "    x = res.x[:n_x].reshape((num_specs, num_tasks))\n",
        "    C = res.x[n_x:]  # capacity provided per specialist\n",
        "    assigned_per_task = x.sum(axis=0)\n",
        "    unmet = np.maximum(req_hours - assigned_per_task, 0.0)\n",
        "\n",
        "    # Summaries\n",
        "    spec_summary_rows = []\n",
        "    for i in range(num_specs):\n",
        "        spec_summary_rows.append({\n",
        "            'spec_id': spec_ids[i],\n",
        "            'fte': float(ftes[i]) if 'ftes' in locals() else 1.0,\n",
        "            'avail_hours': float(avail_hours[i]),\n",
        "            'mandatory_hours': float(mandatory_hours[i]),\n",
        "            'capacity_used_Ci (h)': float(C[i]),\n",
        "            'implied_FTEs': float(C[i] / HOURS_PER_YEAR),\n",
        "            'assigned_hours_sum': float(x[i,:].sum())\n",
        "        })\n",
        "    spec_summary = pd.DataFrame(spec_summary_rows)\n",
        "\n",
        "    task_rows = []\n",
        "    for j,(s,t) in enumerate(task_list):\n",
        "        task_rows.append({\n",
        "            'subspec': s,\n",
        "            'task': t,\n",
        "            'required_h': req_hours[j],\n",
        "            'assigned_h': assigned_per_task[j],\n",
        "            'unmet_h': unmet[j]\n",
        "        })\n",
        "    task_report = pd.DataFrame(task_rows)\n",
        "\n",
        "    # Print results\n",
        "    pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
        "    print(\"\\n=== Task Coverage Summary ===\")\n",
        "    print(task_report.to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== Specialist Capacity Usage Summary ===\")\n",
        "    print(spec_summary.to_string(index=False))\n",
        "\n",
        "    total_capacity = C.sum()\n",
        "    total_FTEs = total_capacity / HOURS_PER_YEAR\n",
        "    total_required = req_hours.sum()\n",
        "    total_assigned = assigned_per_task.sum()\n",
        "    total_unmet = unmet.sum()\n",
        "\n",
        "    print(f\"\\nTotal required hours (all tasks) = {total_required:,.2f} h\")\n",
        "    print(f\"Total assigned hours (sum X_ij)     = {total_assigned:,.2f} h\")\n",
        "    print(f\"Total capacity used (sum C_i)       = {total_capacity:,.2f} h  (≈ {total_FTEs:,.2f} FTE)\")\n",
        "    print(f\"Total unmet hours                   = {total_unmet:,.2f} h\")\n",
        "\n",
        "    if not parsed_clean:\n",
        "        print(\"\\nNote: used conservative fallback (all specialists assumed all-skilled).\")\n",
        "    else:\n",
        "        print(\"\\nNote: specialist parsing used the explicit 'spec_id' + 'skills' format from the specialist sheet.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz4FI28ZxR-N",
        "outputId": "5655cc15-36b2-4e66-8a50-7a23e727547a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'specialist' sheet not in expected clean format (spec_id + skills).\n",
            "Falling back to conservative assumption: 12 full-time all-skilled specialists.\n",
            "Solving corrected LP (minimize total capacity used)...\n",
            "\n",
            "=== Task Coverage Summary ===\n",
            " subspec  task  required_h  assigned_h  unmet_h\n",
            "       1   OPD      780.50      780.50     0.00\n",
            "       1    OR      120.17      120.17     0.00\n",
            "       1  Ward       63.85       63.85     0.00\n",
            "       1 Admin      280.58      280.58     0.00\n",
            "       2   OPD      228.42      228.42     0.00\n",
            "       2    OR       94.83       94.83     0.00\n",
            "       2  Ward       54.20       54.20     0.00\n",
            "       2 Admin      218.00      218.00     0.00\n",
            "       3   OPD      108.10      108.10     0.00\n",
            "       3    OR      118.00      118.00     0.00\n",
            "       3  Ward       28.55       28.55     0.00\n",
            "       3 Admin       92.75       92.75     0.00\n",
            "       4   OPD      754.83      754.83     0.00\n",
            "       4    OR      191.50      191.50     0.00\n",
            "       4  Ward       82.45       82.45     0.00\n",
            "       4 Admin      243.75      243.75     0.00\n",
            "       5   OPD      302.83      302.83     0.00\n",
            "       5    OR       50.17       50.17     0.00\n",
            "       5  Ward       28.40       28.40     0.00\n",
            "       5 Admin      137.00      137.00     0.00\n",
            "       6   OPD      277.00      277.00     0.00\n",
            "       6    OR       50.50       50.50     0.00\n",
            "       6  Ward       25.10       25.10     0.00\n",
            "       6 Admin      144.17      144.17     0.00\n",
            "       7   OPD      206.20      206.20     0.00\n",
            "       7    OR       24.50       24.50     0.00\n",
            "       7  Ward        8.50        8.50     0.00\n",
            "       7 Admin       83.33       83.33     0.00\n",
            "       8   OPD      136.60      136.60     0.00\n",
            "       8    OR       43.17       43.17     0.00\n",
            "       8  Ward       25.85       25.85     0.00\n",
            "       8 Admin      105.42      105.42     0.00\n",
            "       9   OPD      254.92      254.92     0.00\n",
            "       9    OR       38.00       38.00     0.00\n",
            "       9  Ward       17.75       17.75     0.00\n",
            "       9 Admin      161.83      161.83     0.00\n",
            "      10   OPD      343.47      343.47     0.00\n",
            "      10    OR       43.17       43.17     0.00\n",
            "      10  Ward       20.00       20.00     0.00\n",
            "      10 Admin      121.33      121.33     0.00\n",
            "\n",
            "=== Specialist Capacity Usage Summary ===\n",
            "spec_id  fte  avail_hours  mandatory_hours  capacity_used_Ci (h)  implied_FTEs  assigned_hours_sum\n",
            "     S1 1.00     2,080.00           184.00              1,345.03          0.65            1,161.03\n",
            "     S2 1.00     2,080.00           184.00                513.58          0.25              329.58\n",
            "     S3 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "     S4 1.00     2,080.00           184.00              2,080.00          1.00            1,896.00\n",
            "     S5 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "     S6 1.00     2,080.00           184.00              1,720.20          0.83            1,536.20\n",
            "     S7 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "     S8 1.00     2,080.00           184.00              1,142.45          0.55              958.45\n",
            "     S9 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "    S10 1.00     2,080.00           184.00                412.42          0.20              228.42\n",
            "    S11 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "    S12 1.00     2,080.00           184.00                184.00          0.09                0.00\n",
            "\n",
            "Total required hours (all tasks) = 6,109.68 h\n",
            "Total assigned hours (sum X_ij)     = 6,109.68 h\n",
            "Total capacity used (sum C_i)       = 8,317.68 h  (≈ 4.00 FTE)\n",
            "Total unmet hours                   = 0.00 h\n",
            "\n",
            "Note: used conservative fallback (all specialists assumed all-skilled).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uYSWjh97fZB"
      },
      "source": [
        "###Part C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTVLBVolM_ao",
        "outputId": "d8b8e22e-5431-4b5f-9949-5087964a54f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1206766892.py:54: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c], errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Solving MILP (CBC)... this may take a moment.\n",
            "\n",
            "MILP Status: Optimal\n",
            "MILP objective (sum FTE*Z): 4.0\n",
            "Hired specialists (indices): [0, 1, 2, 3]\n",
            "Number hired: 4\n",
            "Sum FTE of hired: 4.0\n",
            "\n",
            "=== Task coverage (MILP) ===\n",
            " subspec  task  required_h  assigned_h  unmet_h\n",
            "       1   OPD      780.50      780.50     0.00\n",
            "       1    OR      120.17      120.17     0.00\n",
            "       1  Ward       63.85       63.85     0.00\n",
            "       1 Admin      280.58      280.58     0.00\n",
            "       2   OPD      228.42      228.42     0.00\n",
            "       2    OR       94.83       94.83     0.00\n",
            "       2  Ward       54.20       54.20     0.00\n",
            "       2 Admin      218.00      218.00     0.00\n",
            "       3   OPD      108.10      108.10     0.00\n",
            "       3    OR      118.00      118.00     0.00\n",
            "       3  Ward       28.55       28.55     0.00\n",
            "       3 Admin       92.75       92.75     0.00\n",
            "       4   OPD      754.83      754.83     0.00\n",
            "       4    OR      191.50      191.50     0.00\n",
            "       4  Ward       82.45       82.45     0.00\n",
            "       4 Admin      243.75      243.75     0.00\n",
            "       5   OPD      302.83      302.83     0.00\n",
            "       5    OR       50.17       50.17     0.00\n",
            "       5  Ward       28.40       28.40     0.00\n",
            "       5 Admin      137.00      137.00     0.00\n",
            "       6   OPD      277.00      277.00     0.00\n",
            "       6    OR       50.50       50.50     0.00\n",
            "       6  Ward       25.10       25.10     0.00\n",
            "       6 Admin      144.17      144.17     0.00\n",
            "       7   OPD      206.20      206.20     0.00\n",
            "       7    OR       24.50       24.50     0.00\n",
            "       7  Ward        8.50        8.50     0.00\n",
            "       7 Admin       83.33      270.10     0.00\n",
            "       8   OPD      136.60      136.60     0.00\n",
            "       8    OR       43.17       43.17     0.00\n",
            "       8  Ward       25.85       25.85     0.00\n",
            "       8 Admin      105.42      105.42     0.00\n",
            "       9   OPD      254.92      254.92     0.00\n",
            "       9    OR       38.00       38.00     0.00\n",
            "       9  Ward       17.75       25.30     0.00\n",
            "       9 Admin      161.83      161.83     0.00\n",
            "      10   OPD      343.47      343.47     0.00\n",
            "      10    OR       43.17       43.17     0.00\n",
            "      10  Ward       20.00       20.00     0.00\n",
            "      10 Admin      121.33      121.33     0.00\n",
            "\n",
            "=== Specialist summary (MILP) ===\n",
            " specialist  FTE  Z_milp  assigned_h  available_h  util_pct_of_avail\n",
            "          0 1.00       1    1,576.00     1,576.00             100.00\n",
            "          1 1.00       1    1,576.00     1,576.00             100.00\n",
            "          2 1.00       1    1,576.00     1,576.00             100.00\n",
            "          3 1.00       1    1,576.00     1,576.00             100.00\n",
            "          4 0.80       0        0.00     1,160.00               0.00\n",
            "          5 0.80       0        0.00     1,160.00               0.00\n",
            "          6 0.80       0        0.00     1,160.00               0.00\n",
            "          7 0.80       0        0.00     1,160.00               0.00\n",
            "          8 0.80       0        0.00     1,160.00               0.00\n",
            "          9 0.80       0        0.00     1,160.00               0.00\n",
            "         10 0.80       0        0.00     1,160.00               0.00\n",
            "         11 0.60       0        0.00       744.00               0.00\n",
            "         12 0.60       0        0.00       744.00               0.00\n",
            "         13 0.60       0        0.00       744.00               0.00\n",
            "         14 0.60       0        0.00       744.00               0.00\n",
            "\n",
            "Saved MILP outputs to CSV: PartC_milp_specialist_summary.csv, PartC_milp_task_coverage.csv\n",
            "\n",
            "Solving LP relaxation (CBC)...\n",
            "LP Status: Optimal\n",
            "LP objective (sum FTE * Z fractional): 3.87670262\n",
            "Nonzero (fractional) Z values from LP (index: value):\n",
            "{0: 1.0, 1: 1.0, 2: 1.0, 3: 0.877}\n",
            "Saved LP Z values to PartC_lp_Z_values.csv\n",
            "\n",
            "=== Comparison ===\n",
            "MILP objective (sum FTE*Z) = 4.0000\n",
            "LP-relax objective (sum FTE * Z fractional) = 3.8767\n",
            "Number hired in MILP: 4\n",
            "Hired indices (MILP): [0, 1, 2, 3]\n",
            "Saved overall summary to PartC_overall_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# Part C - MILP for Capacity Planning\n",
        "!pip install pulp openpyxl --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pulp\n",
        "import math\n",
        "from functools import reduce\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "DATA_PATH = \"Data for Assignment 7.xlsx\"\n",
        "START_H, END_H = 1040, 3120\n",
        "SIM_START_WEEKDAY = 0\n",
        "\n",
        "# Reserved hours per hired specialist\n",
        "HOLIDAY_HOURS = 8 * 5 * 8      # 320\n",
        "CONFERENCE_HOURS = 2 * 5 * 8 + 24  # 104\n",
        "EDUCATION_HOURS = 80\n",
        "RESERVED_PER_HIRED = HOLIDAY_HOURS + CONFERENCE_HOURS + EDUCATION_HOURS  # 504\n",
        "\n",
        "# Upper bound per-variable as in assignment\n",
        "X_UPPER_IF_HIRED = 1600\n",
        "\n",
        "def count_weekdays_in_span(start_weekday: int, length_days: int) -> int:\n",
        "    if length_days <= 0:\n",
        "        return 0\n",
        "    full_weeks, rem = divmod(length_days, 7)\n",
        "    base = full_weeks * 5\n",
        "    cnt = 0\n",
        "    for i in range(rem):\n",
        "        wd = (start_weekday + i) % 7\n",
        "        if wd < 5:\n",
        "            cnt += 1\n",
        "    return base + cnt\n",
        "\n",
        "def avg_weekdays_over_weekday_starts(length_days: int) -> float:\n",
        "    if length_days <= 0:\n",
        "        return 0.0\n",
        "    vals = [count_weekdays_in_span(start_wd, length_days) for start_wd in range(5)]\n",
        "    return sum(vals) / 5.0\n",
        "\n",
        "# ---------- read data ----------\n",
        "xls = pd.ExcelFile(DATA_PATH)\n",
        "patients   = pd.read_excel(xls, \"Patients\")\n",
        "squeue     = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward    = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los   = pd.read_excel(xls, \"surgeryLOS\")\n",
        "specialist = pd.read_excel(xls, sheet_name=\"specialist\", header=None)\n",
        "\n",
        "# coerce numeric columns in patients / squeue / surg_los / in_ward (safe)\n",
        "def coerce_numeric(df):\n",
        "    for c in df.columns:\n",
        "        try:\n",
        "            df[c] = pd.to_numeric(df[c], errors='ignore')\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "for df in [patients, squeue, surg_los, in_ward]:\n",
        "    coerce_numeric(df)\n",
        "\n",
        "# unify name in surgeryLOS if needed\n",
        "if 'subsub' in surg_los.columns and 'subsubsp' not in surg_los.columns:\n",
        "    surg_los = surg_los.rename(columns={'subsub':'subsubsp'})\n",
        "\n",
        "# ---------- PART A demand computation ----------\n",
        "# OPD (backlog-inclusive)\n",
        "patients['arrival (h)'] = pd.to_numeric(patients['arrival (h)'], errors='coerce')\n",
        "patients['timeod (min)'] = pd.to_numeric(patients['timeod (min)'], errors='coerce')\n",
        "patients['subspec'] = pd.to_numeric(patients['subspec'], errors='coerce')\n",
        "\n",
        "opd_year = patients[patients['arrival (h)'] <= END_H].copy()\n",
        "opd_by_sub_min = opd_year.groupby('subspec', dropna=True)['timeod (min)'].sum().rename('OPD minutes').reset_index()\n",
        "\n",
        "# Surgeries in window\n",
        "squeue['subspec'] = pd.to_numeric(squeue['subspec'], errors='coerce')\n",
        "squeue['subsubsp'] = pd.to_numeric(squeue['subsubsp'], errors='coerce')\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "\n",
        "map_cols  = ['subspec', 'subsubsp', 'surgery time(min)', 'LOS(DAYS)']\n",
        "surg_map  = surg_los[[c for c in map_cols if c in surg_los.columns]].drop_duplicates()\n",
        "surg_year = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_m    = surg_year.merge(surg_map, on=['subspec', 'subsubsp'], how='left')\n",
        "\n",
        "# OR minutes per subspecialism\n",
        "if 'surgery time(min)' in surg_m.columns:\n",
        "    or_by_sub_min = surg_m.groupby('subspec', dropna=True)['surgery time(min)'].sum(min_count=1).fillna(0).rename('OR minutes').reset_index()\n",
        "else:\n",
        "    or_by_sub_min = pd.DataFrame({'subspec': [], 'OR minutes': []})\n",
        "\n",
        "# Ward minutes initial (in_ward)\n",
        "in_ward['subspec'] = pd.to_numeric(in_ward['subspec'], errors='coerce')\n",
        "in_ward['remaining LOS'] = pd.to_numeric(in_ward['remaining LOS'], errors='coerce').fillna(0).astype(int)\n",
        "in_ward['ward_days_initial'] = in_ward['remaining LOS'] + 1\n",
        "in_ward['weekday_visits_initial'] = in_ward['ward_days_initial'].apply(lambda k: count_weekdays_in_span(SIM_START_WEEKDAY, k))\n",
        "in_ward['Ward minutes (initial)'] = 15 * in_ward['weekday_visits_initial']\n",
        "ward_init_by_sub_min = in_ward.groupby('subspec', dropna=True)['Ward minutes (initial)'].sum().reset_index()\n",
        "\n",
        "# Ward post-op (from surgeries)\n",
        "if 'LOS(DAYS)' in surg_m.columns:\n",
        "    surg_m['LOS(DAYS)'] = pd.to_numeric(surg_m['LOS(DAYS)'], errors='coerce').fillna(0).astype(int)\n",
        "    surg_m['ward_days_postop'] = surg_m['LOS(DAYS)'] + 1\n",
        "    surg_m['weekday_visits_postop'] = surg_m['ward_days_postop'].apply(avg_weekdays_over_weekday_starts)\n",
        "    surg_m['Ward minutes (post-op)'] = 15 * surg_m['weekday_visits_postop']\n",
        "    ward_postop_by_sub_min = surg_m.groupby('subspec', dropna=True)['Ward minutes (post-op)'].sum().reset_index()\n",
        "else:\n",
        "    ward_postop_by_sub_min = pd.DataFrame({'subspec': [], 'Ward minutes (post-op)': []})\n",
        "\n",
        "# Admin minutes (5 per OPD, 10 per surgery)\n",
        "opd_counts  = opd_year.groupby('subspec', dropna=True).size().rename('OPD count').reset_index()\n",
        "surg_counts = surg_m.groupby('subspec', dropna=True).size().rename('Surgery count').reset_index()\n",
        "admin_opd_by_sub  = opd_counts.assign(admin_minutes_opd  = lambda d: d['OPD count'] * 5)[['subspec','admin_minutes_opd']]\n",
        "admin_surg_by_sub = surg_counts.assign(admin_minutes_surg = lambda d: d['Surgery count'] * 10)[['subspec','admin_minutes_surg']]\n",
        "\n",
        "# Merge per subspecialism\n",
        "dfs = [opd_by_sub_min, or_by_sub_min, ward_postop_by_sub_min, ward_init_by_sub_min, admin_opd_by_sub, admin_surg_by_sub]\n",
        "per_sub = reduce(lambda L, R: L.merge(R, on='subspec', how='outer'), dfs).fillna(0)\n",
        "\n",
        "per_sub['OPD hours']   = per_sub['OPD minutes'] / 60.0\n",
        "per_sub['OR hours']    = per_sub['OR minutes'] / 60.0\n",
        "per_sub['Ward hours']  = (per_sub.get('Ward minutes (post-op)', 0) + per_sub.get('Ward minutes (initial)', 0)) / 60.0\n",
        "per_sub['Admin hours'] = (per_sub.get('admin_minutes_opd', 0) + per_sub.get('admin_minutes_surg', 0)) / 60.0\n",
        "\n",
        "per_sub_table = per_sub[['subspec','OPD hours','OR hours','Ward hours','Admin hours']].sort_values('subspec').reset_index(drop=True)\n",
        "\n",
        "subspecs = sorted(per_sub_table['subspec'].dropna().astype(int).unique().tolist())\n",
        "\n",
        "# Build task list: for each subspec s include tasks OPD, OR, Ward, Admin\n",
        "task_types = ['OPD','OR','Ward','Admin']\n",
        "tasks = []\n",
        "for s in subspecs:\n",
        "    for t in task_types:\n",
        "        tasks.append((t, int(s)))\n",
        "\n",
        "# required hours vector per task (dictionary)\n",
        "demand = {}\n",
        "for (t,s) in tasks:\n",
        "    row = per_sub_table[per_sub_table['subspec']==s]\n",
        "    if row.empty:\n",
        "        demand[(t,s)] = 0.0\n",
        "    else:\n",
        "        demand[(t,s)] = float(row[f\"{t} hours\"].iloc[0])\n",
        "\n",
        "# ---------- Parse specialist sheet to extract skill matrix & FTE ----------\n",
        "spec_raw = specialist.fillna(\"\").astype(str)\n",
        "\n",
        "# Find FTE row (case-insensitive)\n",
        "fte_row_idx = None\n",
        "for r in range(spec_raw.shape[0]):\n",
        "    # join a few cells to detect 'FTE'\n",
        "    rowjoin = \" \".join([str(x).strip().lower() for x in spec_raw.iloc[r, :].tolist()])\n",
        "    if \"fte\" in rowjoin.split():\n",
        "        fte_row_idx = r\n",
        "        break\n",
        "\n",
        "FTE = []\n",
        "num_specialists = None\n",
        "if fte_row_idx is not None:\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        try:\n",
        "            v = float(spec_raw.iat[fte_row_idx, c])\n",
        "            # accept typical FTE values 0 < v <= 1.5\n",
        "            if v >= 0 and v <= 2.5:\n",
        "                FTE.append(v)\n",
        "        except Exception:\n",
        "            pass\n",
        "    num_specialists = len(FTE)\n",
        "\n",
        "if num_specialists is None or num_specialists == 0:\n",
        "    # heuristic: find columns that have many numeric entries (likely specialist columns)\n",
        "    numeric_counts = []\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        count = 0\n",
        "        for r in range(min(30, spec_raw.shape[0])):\n",
        "            try:\n",
        "                _ = float(spec_raw.iat[r,c])\n",
        "                count += 1\n",
        "            except Exception:\n",
        "                pass\n",
        "        numeric_counts.append((c,count))\n",
        "    candidate_cols = [c for c,cnt in numeric_counts if cnt >= 6]\n",
        "    if len(candidate_cols) == 0:\n",
        "        # fallback: assume 12 specialists of FTE 1.0\n",
        "        num_specialists = 12\n",
        "        FTE = [1.0]*num_specialists\n",
        "        candidate_cols = list(range(2, 2+num_specialists))\n",
        "    else:\n",
        "        # infer number of specialists = length of candidate_cols\n",
        "        num_specialists = len(candidate_cols)\n",
        "        FTE = []\n",
        "        for c in candidate_cols:\n",
        "            found = False\n",
        "            for r in range(spec_raw.shape[0]):\n",
        "                try:\n",
        "                    v = float(spec_raw.iat[r,c])\n",
        "                    if 0 <= v <= 2.5:\n",
        "                        FTE.append(v)\n",
        "                        found = True\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "            if not found:\n",
        "                FTE.append(1.0)\n",
        "else:\n",
        "    # we found FTE row; determine specialist columns as numeric entries after first occurrence\n",
        "    # find columns with numeric entries in the FTE row\n",
        "    spec_cols = []\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        try:\n",
        "            v = float(spec_raw.iat[fte_row_idx, c])\n",
        "            # treat as specialist column if within reasonable FTE range\n",
        "            if 0 <= v <= 2.5:\n",
        "                spec_cols.append(c)\n",
        "        except:\n",
        "            pass\n",
        "    if len(spec_cols) >= num_specialists:\n",
        "        candidate_cols = spec_cols[:num_specialists]\n",
        "    else:\n",
        "        # as fallback, take the numeric columns found earlier\n",
        "        candidate_cols = list(range(2, 2+num_specialists))\n",
        "\n",
        "skill_rows = []\n",
        "for r in range(min(40, spec_raw.shape[0])):\n",
        "    rowvals = []\n",
        "    for c in candidate_cols:\n",
        "        val = spec_raw.iat[r,c].strip()\n",
        "        if val in (\"0\",\"1\",\"0.0\",\"1.0\"):\n",
        "            rowvals.append(1)\n",
        "        else:\n",
        "            try:\n",
        "                num = float(val)\n",
        "                if int(num) in (0,1):\n",
        "                    rowvals.append(1)\n",
        "                else:\n",
        "                    rowvals.append(0)\n",
        "            except:\n",
        "                rowvals.append(0)\n",
        "    if sum(rowvals) >= max(3, len(candidate_cols)//2):\n",
        "        skill_rows.append(r)\n",
        "\n",
        "if len(skill_rows) >= 10:\n",
        "    skill_rows = skill_rows[:10]\n",
        "else:\n",
        "    for r in range(spec_raw.shape[0]):\n",
        "        rowstr = \" \".join(spec_raw.iloc[r,:].tolist()).lower()\n",
        "        if \"matrix\" in rowstr or \"skill\" in rowstr:\n",
        "            # take next 10 rows after that\n",
        "            skill_rows = list(range(r+1, r+1+10))\n",
        "            break\n",
        "\n",
        "num_subspec = 10\n",
        "S = {}\n",
        "for i in range(num_specialists):\n",
        "    for s in range(1, num_subspec+1):\n",
        "        S[(i,s)] = 0\n",
        "\n",
        "if skill_rows:\n",
        "    for s_idx, r in enumerate(skill_rows):\n",
        "        if s_idx >= num_subspec:\n",
        "            break\n",
        "        for i, c in enumerate(candidate_cols[:num_specialists]):\n",
        "            try:\n",
        "                val = spec_raw.iat[r, c].strip()\n",
        "                if val in (\"1\",\"1.0\",\"1.00\"):\n",
        "                    S[(i, s_idx+1)] = 1\n",
        "                else:\n",
        "                    try:\n",
        "                        nv = float(val)\n",
        "                        if int(nv) == 1:\n",
        "                            S[(i, s_idx+1)] = 1\n",
        "                        else:\n",
        "                            S[(i, s_idx+1)] = 0\n",
        "                    except:\n",
        "                        S[(i, s_idx+1)] = 0\n",
        "            except Exception:\n",
        "                S[(i, s_idx+1)] = 0\n",
        "else:\n",
        "    for i in range(num_specialists):\n",
        "        for s in range(1, num_subspec+1):\n",
        "            S[(i,s)] = 1\n",
        "\n",
        "if len(FTE) < num_specialists:\n",
        "    FTE = FTE + [1.0] * (num_specialists - len(FTE))\n",
        "elif len(FTE) > num_specialists:\n",
        "    FTE = FTE[:num_specialists]\n",
        "\n",
        "# Convert FTE to floats\n",
        "FTE = [float(x) for x in FTE]\n",
        "\n",
        "sample_skill = [[S[(i,s)] for i in range(min(10, num_specialists))] for s in range(1, num_subspec+1)]\n",
        "\n",
        "# ---------- BUILD MILP ----------\n",
        "prob = pulp.LpProblem(\"PartC_MILP_Capacity_Planning\", pulp.LpMinimize)\n",
        "\n",
        "# Decision vars\n",
        "# X[i,t,s] continuous hours >=0\n",
        "X = {}\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        X[(i,t,s)] = pulp.LpVariable(f\"X_{i}_{t}_{s}\", lowBound=0, cat='Continuous')\n",
        "\n",
        "# Z[i] binary\n",
        "Z = {}\n",
        "for i in range(num_specialists):\n",
        "    Z[i] = pulp.LpVariable(f\"Z_{i}\", cat='Binary')\n",
        "\n",
        "# Objective: minimize sum(FTE_i * Z_i)\n",
        "prob += pulp.lpSum([FTE[i] * Z[i] for i in range(num_specialists)]), \"Minimize_cost_proportional_to_FTE_and_hires\"\n",
        "\n",
        "# Constraints:\n",
        "# 1) Coverage: for each task (t,s): sum_i X[i,t,s] >= demand[(t,s)]\n",
        "for (t,s) in tasks:\n",
        "    prob += pulp.lpSum([ X[(i,t,s)] for i in range(num_specialists) ]) >= demand.get((t,s), 0.0), f\"Demand_{t}_{s}\"\n",
        "\n",
        "# 2) Skill restriction: if specialist i not skilled in subspec s => X[i,t,s] == 0\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        if S.get((i,s), 0) == 0:\n",
        "            prob += X[(i,t,s)] == 0, f\"Skill_block_i{i}_s{s}_{t}\"\n",
        "\n",
        "# 3) Per-variable upper bound: X[i,t,s] <= 1600 * Z[i]\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        prob += X[(i,t,s)] <= X_UPPER_IF_HIRED * Z[i], f\"VarUpper_1600_i{i}_{t}_{s}\"\n",
        "\n",
        "# 4) Specialist total capacity: sum_{tasks} X[i,t,s] <= (2080 * FTE_i - RESERVED_PER_HIRED) * Z_i\n",
        "for i in range(num_specialists):\n",
        "    cap_i = 52 * 40 * FTE[i]  # 2080 * FTE\n",
        "    available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "    # If available_i is 0 or negative then hiring this specialist gives no available work-time; model allows Z_i but will be pointless\n",
        "    prob += pulp.lpSum([ X[(i,t,s)] for (t,s) in tasks ]) <= available_i * Z[i], f\"CapTotal_i_{i}\"\n",
        "\n",
        "# Solve MILP\n",
        "print(\"\\nSolving MILP (CBC)... this may take a moment.\")\n",
        "solver = pulp.PULP_CBC_CMD(msg=1, timeLimit=600, threads=2)  # limit 10 min / 2 threads\n",
        "result = prob.solve(solver)\n",
        "\n",
        "print(\"\\nMILP Status:\", pulp.LpStatus[prob.status])\n",
        "milp_obj = pulp.value(prob.objective)\n",
        "print(\"MILP objective (sum FTE*Z):\", milp_obj)\n",
        "\n",
        "# Collect MILP solution\n",
        "Z_vals_milp = {i: int(round(pulp.value(Z[i]) if pulp.value(Z[i]) is not None else 0)) for i in range(num_specialists)}\n",
        "hired_indices = [i for i,v in Z_vals_milp.items() if v==1]\n",
        "print(\"Hired specialists (indices):\", hired_indices)\n",
        "print(\"Number hired:\", len(hired_indices))\n",
        "print(\"Sum FTE of hired:\", sum(FTE[i] for i in hired_indices))\n",
        "\n",
        "# Compute assigned hours per (t,s) and per specialist\n",
        "assigned_task = { (t,s): 0.0 for (t,s) in tasks }\n",
        "assigned_spec_total = { i: 0.0 for i in range(num_specialists) }\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        val = pulp.value(X[(i,t,s)])\n",
        "        if val is None:\n",
        "            val = 0.0\n",
        "        assigned_task[(t,s)] += val\n",
        "        assigned_spec_total[i] += val\n",
        "\n",
        "# Print task coverage summary\n",
        "print(\"\\n=== Task coverage (MILP) ===\")\n",
        "cov_rows = []\n",
        "for (t,s) in tasks:\n",
        "    req = demand.get((t,s),0.0)\n",
        "    assigned = assigned_task[(t,s)]\n",
        "    unmet = max(0.0, req - assigned)\n",
        "    cov_rows.append((s, t, req, assigned, unmet))\n",
        "cov_df = pd.DataFrame(cov_rows, columns=['subspec','task','required_h','assigned_h','unmet_h'])\n",
        "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
        "print(cov_df.to_string(index=False))\n",
        "\n",
        "# Print specialist utilization summary\n",
        "spec_rows = []\n",
        "for i in range(num_specialists):\n",
        "    cap_i = 52 * 40 * FTE[i]\n",
        "    available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "    spec_rows.append((i, FTE[i], Z_vals_milp[i], assigned_spec_total[i], available_i,\n",
        "                      (assigned_spec_total[i] / available_i * 100.0) if available_i>0 else 0.0))\n",
        "spec_df_out = pd.DataFrame(spec_rows, columns=['specialist','FTE','Z_milp','assigned_h','available_h','util_pct_of_avail'])\n",
        "print(\"\\n=== Specialist summary (MILP) ===\")\n",
        "print(spec_df_out.to_string(index=False))\n",
        "\n",
        "# Save MILP results to CSV\n",
        "spec_df_out.to_csv(\"PartC_milp_specialist_summary.csv\", index=False)\n",
        "cov_df.to_csv(\"PartC_milp_task_coverage.csv\", index=False)\n",
        "print(\"\\nSaved MILP outputs to CSV: PartC_milp_specialist_summary.csv, PartC_milp_task_coverage.csv\")\n",
        "\n",
        "# ---------- LP RELAXATION ----------\n",
        "# Build LP same constraints but Z continuous in [0,1]\n",
        "prob_LP = pulp.LpProblem(\"PartC_LP_relax\", pulp.LpMinimize)\n",
        "Xlp = {}\n",
        "Zlp = {}\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        Xlp[(i,t,s)] = pulp.LpVariable(f\"Xlp_{i}_{t}_{s}\", lowBound=0, cat='Continuous')\n",
        "    Zlp[i] = pulp.LpVariable(f\"Zlp_{i}\", lowBound=0, upBound=1, cat='Continuous')\n",
        "\n",
        "prob_LP += pulp.lpSum([FTE[i] * Zlp[i] for i in range(num_specialists)]), \"LP_relax_objective\"\n",
        "\n",
        "# coverage\n",
        "for (t,s) in tasks:\n",
        "    prob_LP += pulp.lpSum([ Xlp[(i,t,s)] for i in range(num_specialists)]) >= demand.get((t,s),0.0), f\"LP_Demand_{t}_{s}\"\n",
        "\n",
        "# skill & var upper & capacity\n",
        "for i in range(num_specialists):\n",
        "    for (t,s) in tasks:\n",
        "        if S.get((i,s),0) == 0:\n",
        "            prob_LP += Xlp[(i,t,s)] == 0\n",
        "        prob_LP += Xlp[(i,t,s)] <= X_UPPER_IF_HIRED * Zlp[i]\n",
        "    cap_i = 52 * 40 * FTE[i]\n",
        "    available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "    prob_LP += pulp.lpSum([ Xlp[(i,t,s)] for (t,s) in tasks ]) <= available_i * Zlp[i]\n",
        "\n",
        "print(\"\\nSolving LP relaxation (CBC)...\")\n",
        "res_lp = prob_LP.solve(pulp.PULP_CBC_CMD(msg=1, timeLimit=600, threads=2))\n",
        "print(\"LP Status:\", pulp.LpStatus[prob_LP.status])\n",
        "lp_obj = pulp.value(prob_LP.objective)\n",
        "print(\"LP objective (sum FTE * Z fractional):\", lp_obj)\n",
        "\n",
        "Z_vals_lp = {i: pulp.value(Zlp[i]) for i in range(num_specialists)}\n",
        "# print nonzero fractional Zs\n",
        "print(\"Nonzero (fractional) Z values from LP (index: value):\")\n",
        "print({i:round(v,3) for i,v in Z_vals_lp.items() if v is not None and v>1e-6})\n",
        "\n",
        "# Save LP results summary\n",
        "lp_rows = []\n",
        "for i in range(num_specialists):\n",
        "    lp_rows.append({'specialist': i, 'FTE': FTE[i], 'Z_lp': round(pulp.value(Zlp[i]) if pulp.value(Zlp[i]) else 0,4)})\n",
        "pd.DataFrame(lp_rows).to_csv(\"PartC_lp_Z_values.csv\", index=False)\n",
        "print(\"Saved LP Z values to PartC_lp_Z_values.csv\")\n",
        "\n",
        "# ---------- Comparison summary ----------\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(f\"MILP objective (sum FTE*Z) = {milp_obj:.4f}\")\n",
        "print(f\"LP-relax objective (sum FTE * Z fractional) = {lp_obj:.4f}\")\n",
        "print(f\"Number hired in MILP: {len(hired_indices)}\")\n",
        "print(\"Hired indices (MILP):\", hired_indices)\n",
        "\n",
        "# Save overall summary\n",
        "summary = {\n",
        "    'MILP_obj': milp_obj,\n",
        "    'LP_obj': lp_obj,\n",
        "    'num_hired_milp': len(hired_indices),\n",
        "    'sumFTE_hired_milp': sum(FTE[i] for i in hired_indices)\n",
        "}\n",
        "pd.DataFrame([summary]).to_csv(\"PartC_overall_summary.csv\", index=False)\n",
        "print(\"Saved overall summary to PartC_overall_summary.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part D\n"
      ],
      "metadata": {
        "id": "HD56Zm5odfQN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxhEmPBr4SyC",
        "outputId": "9e9945b0-1179-45e4-8374-0e2659cbcf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-291393314.py:61: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c], errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected specialists: 15  |  First few FTEs: [1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
            "Sample skill rows (subspec 1..10, first up to 10 specialists):\n",
            " sub01:  [1, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
            " sub02:  [0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            " sub03:  [1, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            " sub04:  [1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
            " sub05:  [1, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
            " sub06:  [0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
            " sub07:  [1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            " sub08:  [0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
            " sub09:  [0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n",
            " sub10:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
            "\n",
            "=== MILP [base] ===\n",
            "Status: Optimal\n",
            "Objective (sum FTE of hired): 4.0\n",
            "Hired specialists (indices): [0, 1, 2, 3]\n",
            "Number hired: 4\n",
            "Sum FTE (hired): 4.0\n",
            "\n",
            "Task coverage (first 20 rows):\n",
            " subspec  task  required_h  assigned_h  unmet_h\n",
            "       1   OPD      780.50      780.50     0.00\n",
            "       1    OR      120.17      120.17     0.00\n",
            "       1  Ward       63.85       63.85     0.00\n",
            "       1 Admin      280.58      280.58     0.00\n",
            "       2   OPD      228.42      228.42     0.00\n",
            "       2    OR       94.83       94.83     0.00\n",
            "       2  Ward       54.20       54.20     0.00\n",
            "       2 Admin      218.00      218.00     0.00\n",
            "       3   OPD      108.10      108.10     0.00\n",
            "       3    OR      118.00      118.00     0.00\n",
            "       3  Ward       28.55       28.55     0.00\n",
            "       3 Admin       92.75       92.75     0.00\n",
            "       4   OPD      754.83      754.83     0.00\n",
            "       4    OR      191.50      191.50     0.00\n",
            "       4  Ward       82.45       82.45     0.00\n",
            "       4 Admin      243.75      243.75     0.00\n",
            "       5   OPD      302.83      302.83     0.00\n",
            "       5    OR       50.17       50.17     0.00\n",
            "       5  Ward       28.40       28.40     0.00\n",
            "       5 Admin      137.00      137.00     0.00\n",
            "\n",
            "Specialist summary (first 20 rows):\n",
            " specialist  FTE  Z  assigned_h  available_h  util_pct_of_avail\n",
            "          0 1.00  1    1,576.00     1,576.00             100.00\n",
            "          1 1.00  1    1,576.00     1,576.00             100.00\n",
            "          2 1.00  1    1,576.00     1,576.00             100.00\n",
            "          3 1.00  1    1,576.00     1,576.00             100.00\n",
            "          4 0.80  0        0.00     1,160.00               0.00\n",
            "          5 0.80  0        0.00     1,160.00               0.00\n",
            "          6 0.80  0        0.00     1,160.00               0.00\n",
            "          7 0.80  0        0.00     1,160.00               0.00\n",
            "          8 0.80  0        0.00     1,160.00               0.00\n",
            "          9 0.80  0        0.00     1,160.00               0.00\n",
            "         10 0.80  0        0.00     1,160.00               0.00\n",
            "         11 0.60  0        0.00       744.00               0.00\n",
            "         12 0.60  0        0.00       744.00               0.00\n",
            "         13 0.60  0        0.00       744.00               0.00\n",
            "         14 0.60  0        0.00       744.00               0.00\n",
            "\n",
            "Saved: PartD_base_task_coverage.csv, PartD_base_specialist_summary.csv\n",
            "\n",
            "=== MILP [slack_20] ===\n",
            "Status: Optimal\n",
            "Objective (sum FTE of hired): 4.8\n",
            "Hired specialists (indices): [0, 1, 2, 3, 4]\n",
            "Number hired: 5\n",
            "Sum FTE (hired): 4.8\n",
            "\n",
            "Task coverage (first 20 rows):\n",
            " subspec  task  required_h  assigned_h  unmet_h\n",
            "       1   OPD      936.60      936.60     0.00\n",
            "       1    OR      144.20      144.20     0.00\n",
            "       1  Ward       76.62       76.62     0.00\n",
            "       1 Admin      336.70      336.70     0.00\n",
            "       2   OPD      274.10      274.10     0.00\n",
            "       2    OR      113.80      113.80     0.00\n",
            "       2  Ward       65.04       65.04     0.00\n",
            "       2 Admin      261.60      261.60     0.00\n",
            "       3   OPD      129.72      129.72     0.00\n",
            "       3    OR      141.60      141.60     0.00\n",
            "       3  Ward       34.26       34.26     0.00\n",
            "       3 Admin      111.30      111.30     0.00\n",
            "       4   OPD      905.80      905.80     0.00\n",
            "       4    OR      229.80      229.80     0.00\n",
            "       4  Ward       98.94       98.94     0.00\n",
            "       4 Admin      292.50      292.50     0.00\n",
            "       5   OPD      363.40      363.40     0.00\n",
            "       5    OR       60.20       60.20     0.00\n",
            "       5  Ward       34.08       34.08     0.00\n",
            "       5 Admin      164.40      164.40     0.00\n",
            "\n",
            "Specialist summary (first 20 rows):\n",
            " specialist  FTE  Z  assigned_h  available_h  util_pct_of_avail\n",
            "          0 1.00  1    1,576.00     1,576.00             100.00\n",
            "          1 1.00  1    1,576.00     1,576.00             100.00\n",
            "          2 1.00  1    1,576.00     1,576.00             100.00\n",
            "          3 1.00  1    1,576.00     1,576.00             100.00\n",
            "          4 0.80  1    1,160.00     1,160.00             100.00\n",
            "          5 0.80  0        0.00     1,160.00               0.00\n",
            "          6 0.80  0        0.00     1,160.00               0.00\n",
            "          7 0.80  0        0.00     1,160.00               0.00\n",
            "          8 0.80  0        0.00     1,160.00               0.00\n",
            "          9 0.80  0        0.00     1,160.00               0.00\n",
            "         10 0.80  0        0.00     1,160.00               0.00\n",
            "         11 0.60  0        0.00       744.00               0.00\n",
            "         12 0.60  0        0.00       744.00               0.00\n",
            "         13 0.60  0        0.00       744.00               0.00\n",
            "         14 0.60  0        0.00       744.00               0.00\n",
            "\n",
            "Saved: PartD_slack_20_task_coverage.csv, PartD_slack_20_specialist_summary.csv\n",
            "\n",
            "\n",
            "=== Part D — Comparison Summary ===\n",
            "                           Metric  Slack 20%  Base 0%  Delta (Slack - Base)  % Change vs Base\n",
            "     Objective (sum FTE of hires)       4.80     4.00                  0.80             20.00\n",
            "              # Hired specialists       5.00     4.00                  1.00               NaN\n",
            "                  Sum FTE (hired)       4.80     4.00                  0.80             20.00\n",
            "Required hours (total over tasks)   7,331.62 6,109.68              1,221.94             20.00\n",
            "             Assigned hours (sum)   7,464.00 6,304.00              1,160.00             18.40\n",
            "                Unmet hours (sum)       0.00     0.00                 -0.00           -100.00\n",
            "\n",
            "Saved comparison CSV: PartD_comparison_summary_20pct.csv\n",
            "\n",
            "=== Brief Commentary (auto-generated) ===\n",
            "- Applied slack of 20% to all task demands.\n",
            "- Total required hours increased by ~20.0% (as expected).\n",
            "- Model hires 1 more specialist(s) compared to the no-slack solution.\n",
            "- Objective (sum FTE of hires) changed by +0.80.\n",
            "- Slack model covers all (slack-adjusted) demand (no unmet hours).\n",
            "- See CSV outputs for full details per task and per specialist.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Assignment 7 — Part D (Google Colab-ready)\n",
        "# Capacity Planning with Required Slack (e.g., +10% or +20%)\n",
        "#\n",
        "# Paste this into a Colab cell. Upload your Excel (e.g.,\n",
        "# \"Data for Assignment 7.xlsx\" or \"Data for Assignment 7 (3).xlsx\")\n",
        "# into the Colab working directory first.\n",
        "# ============================================\n",
        "\n",
        "!pip -q install pulp openpyxl pandas numpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pulp\n",
        "from functools import reduce\n",
        "import math\n",
        "import os\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "# Try a few common file names; use the first that exists.\n",
        "CANDIDATE_DATA_PATHS = [\"Data for Assignment 7.xlsx\"]\n",
        "DATA_PATH = next((p for p in CANDIDATE_DATA_PATHS if os.path.exists(p)), CANDIDATE_DATA_PATHS[0])\n",
        "\n",
        "START_H, END_H = 1040, 3120       # planning window [inclusive]\n",
        "SIM_START_WEEKDAY = 0             # Monday as in Parts A–C\n",
        "\n",
        "# CHOOSE YOUR SLACK HERE (e.g., 0.10 = +10%, 0.20 = +20%)\n",
        "SLACK_PCT = 0.20\n",
        "\n",
        "# Reserved hours per hired specialist (fixed per Part C)\n",
        "HOLIDAY_HOURS = 8 * 5 * 8          # 320\n",
        "CONFERENCE_HOURS = 2 * 5 * 8 + 24  # 104\n",
        "EDUCATION_HOURS = 80\n",
        "RESERVED_PER_HIRED = HOLIDAY_HOURS + CONFERENCE_HOURS + EDUCATION_HOURS  # 504\n",
        "\n",
        "# Upper bound per variable (per task/subspec/specialist)\n",
        "X_UPPER_IF_HIRED = 1600\n",
        "\n",
        "# ---------- Helper functions (weekday-aware, same logic as Parts A/B/C) ----------\n",
        "def count_weekdays_in_span(start_weekday: int, length_days: int) -> int:\n",
        "    if length_days <= 0:\n",
        "        return 0\n",
        "    full_weeks, rem = divmod(length_days, 7)\n",
        "    base = full_weeks * 5\n",
        "    cnt = 0\n",
        "    for i in range(rem):\n",
        "        wd = (start_weekday + i) % 7\n",
        "        if wd < 5:\n",
        "            cnt += 1\n",
        "    return base + cnt\n",
        "\n",
        "def avg_weekdays_over_weekday_starts(length_days: int) -> float:\n",
        "    if length_days <= 0:\n",
        "        return 0.0\n",
        "    vals = [count_weekdays_in_span(start_wd, length_days) for start_wd in range(5)]  # Mon..Fri start\n",
        "    return sum(vals) / 5.0\n",
        "\n",
        "def coerce_numeric(df: pd.DataFrame):\n",
        "    for c in df.columns:\n",
        "        try:\n",
        "            df[c] = pd.to_numeric(df[c], errors='ignore')\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# ---------- Load data ----------\n",
        "xls = pd.ExcelFile(DATA_PATH)\n",
        "patients   = pd.read_excel(xls, \"Patients\")\n",
        "squeue     = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward    = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los   = pd.read_excel(xls, \"surgeryLOS\")\n",
        "# Specialist sheet format can vary; read without header to robustly parse\n",
        "specialist = pd.read_excel(xls, sheet_name=\"specialist\", header=None)\n",
        "\n",
        "# ---------- Clean / unify ----------\n",
        "for df in [patients, squeue, surg_los, in_ward]:\n",
        "    coerce_numeric(df)\n",
        "\n",
        "# unify LOS mapping columns\n",
        "if 'subsub' in surg_los.columns and 'subsubsp' not in surg_los.columns:\n",
        "    surg_los = surg_los.rename(columns={'subsub':'subsubsp'})\n",
        "\n",
        "# ---------- Part A-style demand computation ----------\n",
        "# OPD (backlog-inclusive) — all first-visit arrivals with arrival(h) <= END_H\n",
        "patients['arrival (h)'] = pd.to_numeric(patients['arrival (h)'], errors='coerce')\n",
        "patients['timeod (min)'] = pd.to_numeric(patients['timeod (min)'], errors='coerce')\n",
        "patients['subspec'] = pd.to_numeric(patients['subspec'], errors='coerce')\n",
        "\n",
        "opd_year = patients[patients['arrival (h)'] <= END_H].copy()\n",
        "opd_by_sub_min = (\n",
        "    opd_year.groupby('subspec', dropna=True)['timeod (min)']\n",
        "    .sum().rename('OPD minutes').reset_index()\n",
        ")\n",
        "\n",
        "# Surgeries in the window by due-date\n",
        "squeue['subspec'] = pd.to_numeric(squeue['subspec'], errors='coerce')\n",
        "squeue['subsubsp'] = pd.to_numeric(squeue['subsubsp'], errors='coerce')\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "\n",
        "map_cols  = ['subspec', 'subsubsp', 'surgery time(min)', 'LOS(DAYS)']\n",
        "surg_map  = surg_los[[c for c in map_cols if c in surg_los.columns]].drop_duplicates()\n",
        "surg_year = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_m    = surg_year.merge(surg_map, on=['subspec', 'subsubsp'], how='left')\n",
        "\n",
        "# OR minutes\n",
        "if 'surgery time(min)' in surg_m.columns:\n",
        "    or_by_sub_min = (\n",
        "        surg_m.groupby('subspec', dropna=True)['surgery time(min)']\n",
        "        .sum(min_count=1).fillna(0)\n",
        "        .rename('OR minutes').reset_index()\n",
        "    )\n",
        "else:\n",
        "    or_by_sub_min = pd.DataFrame({'subspec': [], 'OR minutes': []})\n",
        "\n",
        "# Ward minutes — initial (in-ward at t=1040): exact weekday count from Monday\n",
        "in_ward['subspec'] = pd.to_numeric(in_ward['subspec'], errors='coerce')\n",
        "in_ward['remaining LOS'] = pd.to_numeric(in_ward['remaining LOS'], errors='coerce').fillna(0).astype(int)\n",
        "in_ward['ward_days_initial'] = in_ward['remaining LOS'] + 1\n",
        "in_ward['weekday_visits_initial'] = in_ward['ward_days_initial'].apply(lambda k: count_weekdays_in_span(SIM_START_WEEKDAY, k))\n",
        "in_ward['Ward minutes (initial)'] = 15 * in_ward['weekday_visits_initial']\n",
        "ward_init_by_sub_min = (\n",
        "    in_ward.groupby('subspec', dropna=True)['Ward minutes (initial)']\n",
        "    .sum().reset_index()\n",
        ")\n",
        "\n",
        "# Ward minutes — post-op (average weekdays over Mon–Fri surgery starts)\n",
        "if 'LOS(DAYS)' in surg_m.columns:\n",
        "    surg_m['LOS(DAYS)'] = pd.to_numeric(surg_m['LOS(DAYS)'], errors='coerce').fillna(0).astype(int)\n",
        "    surg_m['ward_days_postop'] = surg_m['LOS(DAYS)'] + 1\n",
        "    surg_m['weekday_visits_postop'] = surg_m['ward_days_postop'].apply(avg_weekdays_over_weekday_starts)\n",
        "    surg_m['Ward minutes (post-op)'] = 15 * surg_m['weekday_visits_postop']\n",
        "    ward_postop_by_sub_min = (\n",
        "        surg_m.groupby('subspec', dropna=True)['Ward minutes (post-op)']\n",
        "        .sum().reset_index()\n",
        "    )\n",
        "else:\n",
        "    ward_postop_by_sub_min = pd.DataFrame({'subspec': [], 'Ward minutes (post-op)': []})\n",
        "\n",
        "# Admin (5 min per OPD first visit; 10 min per surgery)\n",
        "opd_counts  = opd_year.groupby('subspec', dropna=True).size().rename('OPD count').reset_index()\n",
        "surg_counts = surg_m.groupby('subspec', dropna=True).size().rename('Surgery count').reset_index()\n",
        "admin_opd_by_sub  = opd_counts.assign(admin_minutes_opd  = lambda d: d['OPD count'] * 5)[['subspec','admin_minutes_opd']]\n",
        "admin_surg_by_sub = surg_counts.assign(admin_minutes_surg = lambda d: d['Surgery count'] * 10)[['subspec','admin_minutes_surg']]\n",
        "\n",
        "dfs = [\n",
        "    opd_by_sub_min,\n",
        "    or_by_sub_min,\n",
        "    ward_postop_by_sub_min,\n",
        "    ward_init_by_sub_min,\n",
        "    admin_opd_by_sub,\n",
        "    admin_surg_by_sub\n",
        "]\n",
        "per_sub = reduce(lambda L, R: L.merge(R, on='subspec', how='outer'), dfs).fillna(0)\n",
        "\n",
        "per_sub['OPD hours']   = per_sub['OPD minutes'] / 60.0\n",
        "per_sub['OR hours']    = per_sub['OR minutes'] / 60.0\n",
        "per_sub['Ward hours']  = (per_sub.get('Ward minutes (post-op)', 0) + per_sub.get('Ward minutes (initial)', 0)) / 60.0\n",
        "per_sub['Admin hours'] = (per_sub.get('admin_minutes_opd', 0) + per_sub.get('admin_minutes_surg', 0)) / 60.0\n",
        "per_sub_table = per_sub[['subspec','OPD hours','OR hours','Ward hours','Admin hours']].sort_values('subspec').reset_index(drop=True)\n",
        "\n",
        "# Task list per subspecialism\n",
        "task_types = ['OPD','OR','Ward','Admin']\n",
        "subspecs = sorted(per_sub_table['subspec'].dropna().astype(int).unique().tolist())\n",
        "tasks = [(t, s) for s in subspecs for t in task_types]\n",
        "\n",
        "# Required hours dict\n",
        "demand_base = {}\n",
        "for (t,s) in tasks:\n",
        "    row = per_sub_table[per_sub_table['subspec'] == s]\n",
        "    demand_base[(t,s)] = float(row[f\"{t} hours\"].iloc[0]) if not row.empty else 0.0\n",
        "\n",
        "# ---------- Parse specialist sheet → FTE & Skill matrix (robust heuristic as in Part C) ----------\n",
        "spec_raw = specialist.fillna(\"\").astype(str)\n",
        "\n",
        "# Locate a row containing 'FTE' (case-insensitive) to get FTE values\n",
        "fte_row_idx = None\n",
        "for r in range(spec_raw.shape[0]):\n",
        "    row_tokens = \" \".join([str(x).strip().lower() for x in spec_raw.iloc[r, :].tolist()]).split()\n",
        "    if \"fte\" in row_tokens:\n",
        "        fte_row_idx = r\n",
        "        break\n",
        "\n",
        "FTE = []\n",
        "num_specialists = None\n",
        "if fte_row_idx is not None:\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        try:\n",
        "            v = float(spec_raw.iat[fte_row_idx, c])\n",
        "            if 0 <= v <= 2.5:  # plausible FTE\n",
        "                FTE.append(v)\n",
        "        except Exception:\n",
        "            pass\n",
        "    num_specialists = len(FTE)\n",
        "\n",
        "# If not found, detect candidate specialist columns by numeric density\n",
        "if num_specialists is None or num_specialists == 0:\n",
        "    numeric_counts = []\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        cnt = 0\n",
        "        for r in range(min(30, spec_raw.shape[0])):\n",
        "            try:\n",
        "                _ = float(spec_raw.iat[r, c])\n",
        "                cnt += 1\n",
        "            except:\n",
        "                pass\n",
        "        numeric_counts.append((c, cnt))\n",
        "    candidate_cols = [c for c, cnt in numeric_counts if cnt >= 6]\n",
        "    if len(candidate_cols) == 0:\n",
        "        num_specialists = 12\n",
        "        FTE = [1.0] * num_specialists\n",
        "        candidate_cols = list(range(2, 2 + num_specialists))\n",
        "    else:\n",
        "        num_specialists = len(candidate_cols)\n",
        "        FTE = []\n",
        "        for c in candidate_cols:\n",
        "            found = False\n",
        "            for r in range(spec_raw.shape[0]):\n",
        "                try:\n",
        "                    v = float(spec_raw.iat[r, c])\n",
        "                    if 0 <= v <= 2.5:\n",
        "                        FTE.append(v)\n",
        "                        found = True\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "            if not found:\n",
        "                FTE.append(1.0)\n",
        "else:\n",
        "    # columns where the FTE row has numeric entries are likely the specialist columns\n",
        "    spec_cols = []\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        try:\n",
        "            v = float(spec_raw.iat[fte_row_idx, c])\n",
        "            if 0 <= v <= 2.5:\n",
        "                spec_cols.append(c)\n",
        "        except:\n",
        "            pass\n",
        "    candidate_cols = spec_cols[:num_specialists] if len(spec_cols) >= num_specialists else list(range(2, 2 + num_specialists))\n",
        "\n",
        "# Detect skill rows (rows with many 0/1-like entries across candidate_cols)\n",
        "skill_rows = []\n",
        "for r in range(min(40, spec_raw.shape[0])):\n",
        "    flags = []\n",
        "    for c in candidate_cols[:num_specialists]:\n",
        "        val = spec_raw.iat[r, c].strip()\n",
        "        if val in (\"0\",\"1\",\"0.0\",\"1.0\"):\n",
        "            flags.append(1)\n",
        "        else:\n",
        "            try:\n",
        "                num = float(val)\n",
        "                flags.append(1 if int(num) in (0,1) else 0)\n",
        "            except:\n",
        "                flags.append(0)\n",
        "    if sum(flags) >= max(3, len(candidate_cols)//2):\n",
        "        skill_rows.append(r)\n",
        "\n",
        "# Expect ~10 subspec rows\n",
        "num_subspec = 10\n",
        "if len(skill_rows) >= 10:\n",
        "    skill_rows = skill_rows[:10]\n",
        "else:\n",
        "    # fallback: try to find a row that mentions 'matrix' or 'skill' and take next 10\n",
        "    for r in range(spec_raw.shape[0]):\n",
        "        rowstr = \" \".join(spec_raw.iloc[r, :].tolist()).lower()\n",
        "        if \"matrix\" in rowstr or \"skill\" in rowstr:\n",
        "            skill_rows = list(range(r+1, r+1+10))\n",
        "            break\n",
        "\n",
        "# Build skill matrix S[(i,s)] in {0,1}\n",
        "S = {(i, s): 0 for i in range(num_specialists) for s in range(1, num_subspec+1)}\n",
        "if skill_rows:\n",
        "    for s_idx, r in enumerate(skill_rows):\n",
        "        if s_idx >= num_subspec:\n",
        "            break\n",
        "        for i, c in enumerate(candidate_cols[:num_specialists]):\n",
        "            try:\n",
        "                val = spec_raw.iat[r, c].strip()\n",
        "                if val in (\"1\",\"1.0\",\"1.00\"):\n",
        "                    S[(i, s_idx+1)] = 1\n",
        "                else:\n",
        "                    nv = float(val)\n",
        "                    S[(i, s_idx+1)] = 1 if int(nv) == 1 else 0\n",
        "            except:\n",
        "                S[(i, s_idx+1)] = 0\n",
        "else:\n",
        "    # fallback: all skilled\n",
        "    for i in range(num_specialists):\n",
        "        for s in range(1, num_subspec+1):\n",
        "            S[(i, s)] = 1\n",
        "\n",
        "# Normalize FTE vector length\n",
        "if len(FTE) < num_specialists:\n",
        "    FTE = FTE + [1.0] * (num_specialists - len(FTE))\n",
        "elif len(FTE) > num_specialists:\n",
        "    FTE = FTE[:num_specialists]\n",
        "FTE = [float(x) for x in FTE]\n",
        "\n",
        "print(f\"Detected specialists: {num_specialists}  |  First few FTEs: {FTE[:min(10, len(FTE))]}\")\n",
        "print(\"Sample skill rows (subspec 1..10, first up to 10 specialists):\")\n",
        "for s in range(1, num_subspec+1):\n",
        "    print(f\" sub{s:02d}: \", [S[(i, s)] for i in range(min(10, num_specialists))])\n",
        "\n",
        "# ---------- MILP builder/solver ----------\n",
        "def solve_milp(demand_dict, slack_pct=0.0, label=\"base\", time_limit_sec=600, threads=2):\n",
        "    \"\"\"\n",
        "    demand_dict: dict mapping (task, subspec) -> required hours\n",
        "    slack_pct:   e.g., 0.2 for +20% slack\n",
        "    label:       string suffix for output file names\n",
        "    \"\"\"\n",
        "    # Apply slack multiplier\n",
        "    req = {k: v*(1.0 + slack_pct) for k, v in demand_dict.items()}\n",
        "\n",
        "    # Build model\n",
        "    prob = pulp.LpProblem(f\"PartD_MILP_{label}\", pulp.LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    X = {}  # hours assigned\n",
        "    for i in range(num_specialists):\n",
        "        for (t, s) in tasks:\n",
        "            X[(i, t, s)] = pulp.LpVariable(f\"X_{i}_{t}_{s}_{label}\", lowBound=0, cat='Continuous')\n",
        "    Z = {i: pulp.LpVariable(f\"Z_{i}_{label}\", cat='Binary') for i in range(num_specialists)}\n",
        "\n",
        "    # Objective: minimize sum(FTE_i * Z_i)\n",
        "    prob += pulp.lpSum([FTE[i] * Z[i] for i in range(num_specialists)]), \"Minimize_sum_FTE_of_hires\"\n",
        "\n",
        "    # Coverage constraints\n",
        "    for (t, s) in tasks:\n",
        "        prob += pulp.lpSum([X[(i, t, s)] for i in range(num_specialists)]) >= req.get((t, s), 0.0), f\"Demand_{t}_{s}\"\n",
        "\n",
        "    # Skill restrictions and variable upper bounds\n",
        "    for i in range(num_specialists):\n",
        "        for (t, s) in tasks:\n",
        "            if S.get((i, s), 0) == 0:\n",
        "                prob += X[(i, t, s)] == 0, f\"SkillBlock_i{i}_s{s}_{t}\"\n",
        "            prob += X[(i, t, s)] <= X_UPPER_IF_HIRED * Z[i], f\"VarUpper_i{i}_{t}_{s}\"\n",
        "\n",
        "    # Total capacity per specialist\n",
        "    for i in range(num_specialists):\n",
        "        cap_i = 52 * 40 * FTE[i]  # 2080 * FTE\n",
        "        available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "        prob += pulp.lpSum([X[(i, t, s)] for (t, s) in tasks]) <= available_i * Z[i], f\"CapTotal_i{i}\"\n",
        "\n",
        "    # Solve\n",
        "    solver = pulp.PULP_CBC_CMD(msg=1, timeLimit=time_limit_sec, threads=threads)\n",
        "    _ = prob.solve(solver)\n",
        "\n",
        "    # Gather results\n",
        "    status = pulp.LpStatus[prob.status]\n",
        "    obj = pulp.value(prob.objective)\n",
        "\n",
        "    Z_vals = {i: int(round(pulp.value(Z[i]) if pulp.value(Z[i]) is not None else 0)) for i in range(num_specialists)}\n",
        "    hired = [i for i, z in Z_vals.items() if z == 1]\n",
        "    sumFTE_hired = sum(FTE[i] for i in hired)\n",
        "\n",
        "    assigned_task = {(t, s): 0.0 for (t, s) in tasks}\n",
        "    assigned_spec = {i: 0.0 for i in range(num_specialists)}\n",
        "    for i in range(num_specialists):\n",
        "        for (t, s) in tasks:\n",
        "            val = pulp.value(X[(i, t, s)])\n",
        "            if val is None:\n",
        "                val = 0.0\n",
        "            assigned_task[(t, s)] += val\n",
        "            assigned_spec[i] += val\n",
        "\n",
        "    # Build dataframes\n",
        "    cov_rows = []\n",
        "    for (t, s) in tasks:\n",
        "        required = req.get((t, s), 0.0)\n",
        "        assigned = assigned_task[(t, s)]\n",
        "        unmet = max(0.0, required - assigned)\n",
        "        cov_rows.append((s, t, required, assigned, unmet))\n",
        "    cov_df = pd.DataFrame(cov_rows, columns=['subspec', 'task', 'required_h', 'assigned_h', 'unmet_h'])\n",
        "\n",
        "    spec_rows = []\n",
        "    for i in range(num_specialists):\n",
        "        cap_i = 52 * 40 * FTE[i]\n",
        "        available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "        util = (assigned_spec[i] / available_i * 100.0) if available_i > 0 else 0.0\n",
        "        spec_rows.append((i, FTE[i], Z_vals[i], assigned_spec[i], available_i, util))\n",
        "    spec_df = pd.DataFrame(spec_rows, columns=['specialist', 'FTE', 'Z', 'assigned_h', 'available_h', 'util_pct_of_avail'])\n",
        "\n",
        "    # Save CSVs\n",
        "    cov_df.to_csv(f\"PartD_{label}_task_coverage.csv\", index=False)\n",
        "    spec_df.to_csv(f\"PartD_{label}_specialist_summary.csv\", index=False)\n",
        "\n",
        "    # Console prints\n",
        "    pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
        "    print(f\"\\n=== MILP [{label}] ===\")\n",
        "    print(\"Status:\", status)\n",
        "    print(\"Objective (sum FTE of hired):\", obj)\n",
        "    print(\"Hired specialists (indices):\", hired)\n",
        "    print(\"Number hired:\", len(hired))\n",
        "    print(\"Sum FTE (hired):\", sumFTE_hired)\n",
        "    print(\"\\nTask coverage (first 20 rows):\")\n",
        "    print(cov_df.head(20).to_string(index=False))\n",
        "    print(\"\\nSpecialist summary (first 20 rows):\")\n",
        "    print(spec_df.head(20).to_string(index=False))\n",
        "    print(f\"\\nSaved: PartD_{label}_task_coverage.csv, PartD_{label}_specialist_summary.csv\")\n",
        "\n",
        "    return {\n",
        "        \"status\": status,\n",
        "        \"obj\": obj,\n",
        "        \"num_hired\": len(hired),\n",
        "        \"sumFTE_hired\": sumFTE_hired,\n",
        "        \"cov_df\": cov_df,\n",
        "        \"spec_df\": spec_df,\n",
        "        \"hired_indices\": hired,\n",
        "        \"required_total_h\": sum(req.values()),\n",
        "        \"assigned_total_h\": cov_df['assigned_h'].sum(),\n",
        "        \"unmet_total_h\": cov_df['unmet_h'].sum(),\n",
        "        \"slack_pct\": slack_pct\n",
        "    }\n",
        "\n",
        "# ---------- Solve baseline (no slack) vs. slack ----------\n",
        "res_base  = solve_milp(demand_base, slack_pct=0.0, label=\"base\")\n",
        "res_slack = solve_milp(demand_base, slack_pct=SLACK_PCT, label=f\"slack_{int(SLACK_PCT*100)}\")\n",
        "\n",
        "# ---------- Comparison & simple commentary ----------\n",
        "def pct(x, y):\n",
        "    return (100.0 * (x - y) / y) if y and y != 0 else (np.nan if y == 0 and x == 0 else np.inf)\n",
        "\n",
        "cmp_rows = []\n",
        "cmp_rows.append((\"Objective (sum FTE of hires)\", res_slack[\"obj\"], res_base[\"obj\"], res_slack[\"obj\"] - res_base[\"obj\"], pct(res_slack[\"obj\"], res_base[\"obj\"])))\n",
        "cmp_rows.append((\"# Hired specialists\", res_slack[\"num_hired\"], res_base[\"num_hired\"], res_slack[\"num_hired\"] - res_base[\"num_hired\"], np.nan))\n",
        "cmp_rows.append((\"Sum FTE (hired)\", res_slack[\"sumFTE_hired\"], res_base[\"sumFTE_hired\"], res_slack[\"sumFTE_hired\"] - res_base[\"sumFTE_hired\"], pct(res_slack[\"sumFTE_hired\"], res_base[\"sumFTE_hired\"])))\n",
        "cmp_rows.append((\"Required hours (total over tasks)\", res_slack[\"required_total_h\"], res_base[\"required_total_h\"], res_slack[\"required_total_h\"] - res_base[\"required_total_h\"], pct(res_slack[\"required_total_h\"], res_base[\"required_total_h\"])))\n",
        "cmp_rows.append((\"Assigned hours (sum)\", res_slack[\"assigned_total_h\"], res_base[\"assigned_total_h\"], res_slack[\"assigned_total_h\"] - res_base[\"assigned_total_h\"], pct(res_slack[\"assigned_total_h\"], res_base[\"assigned_total_h\"])))\n",
        "cmp_rows.append((\"Unmet hours (sum)\", res_slack[\"unmet_total_h\"], res_base[\"unmet_total_h\"], res_slack[\"unmet_total_h\"] - res_base[\"unmet_total_h\"], pct(res_slack[\"unmet_total_h\"], res_base[\"unmet_total_h\"]) if res_base[\"unmet_total_h\"] else np.nan))\n",
        "\n",
        "cmp_df = pd.DataFrame(cmp_rows, columns=[\"Metric\", f\"Slack {int(SLACK_PCT*100)}%\", \"Base 0%\", \"Delta (Slack - Base)\", \"% Change vs Base\"])\n",
        "cmp_df.to_csv(f\"PartD_comparison_summary_{int(SLACK_PCT*100)}pct.csv\", index=False)\n",
        "\n",
        "print(\"\\n\\n=== Part D — Comparison Summary ===\")\n",
        "pd.set_option('display.float_format', lambda v: f\"{v:,.2f}\")\n",
        "print(cmp_df.to_string(index=False))\n",
        "print(f\"\\nSaved comparison CSV: PartD_comparison_summary_{int(SLACK_PCT*100)}pct.csv\")\n",
        "\n",
        "# High-level auto-commentary printed to console\n",
        "delta_hires = res_slack[\"num_hired\"] - res_base[\"num_hired\"]\n",
        "delta_obj = res_slack[\"obj\"] - res_base[\"obj\"]\n",
        "delta_req_pct = pct(res_slack[\"required_total_h\"], res_base[\"required_total_h\"])\n",
        "\n",
        "print(\"\\n=== Brief Commentary (auto-generated) ===\")\n",
        "print(f\"- Applied slack of {int(SLACK_PCT*100)}% to all task demands.\")\n",
        "print(f\"- Total required hours increased by ~{delta_req_pct:.1f}% (as expected).\")\n",
        "if delta_hires > 0:\n",
        "    print(f\"- Model hires {delta_hires} more specialist(s) compared to the no-slack solution.\")\n",
        "elif delta_hires == 0:\n",
        "    print(f\"- Model hires the same number of specialists; hours are reallocated to meet the higher demand.\")\n",
        "else:\n",
        "    print(f\"- Model hires fewer specialists (unexpected under slack); check skill/capacity constraints and data.\")\n",
        "print(f\"- Objective (sum FTE of hires) changed by {delta_obj:+.2f}.\")\n",
        "if res_slack[\"unmet_total_h\"] > 1e-6:\n",
        "    print(f\"- Slack model still shows unmet hours ({res_slack['unmet_total_h']:.2f} h). Consider raising staffing or revisiting constraints.\")\n",
        "else:\n",
        "    print(f\"- Slack model covers all (slack-adjusted) demand (no unmet hours).\")\n",
        "print(\"- See CSV outputs for full details per task and per specialist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWEoTCG-Z0-u"
      },
      "source": [
        "### Part E\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part E1"
      ],
      "metadata": {
        "id": "p-PgABm-eN71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Assignment 7 - Part E1: IMPROVED Weekly Schedule Construction\n",
        "# Fixes: Coverage constraints, proper hour allocation, session-based scheduling\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pulp\n",
        "from functools import reduce\n",
        "import os\n",
        "import math\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "DATA_PATH = \"Data for Assignment 7.xlsx\"\n",
        "WEEKS = 52\n",
        "HOURS_PER_WEEK = 40\n",
        "\n",
        "# Leave requirements from assignment (per specialist per year)\n",
        "HOLIDAY_WEEKS_REQUIRED = 8\n",
        "CONFERENCE_WEEKS = 2\n",
        "EDUCATION_HOURS_YEAR = 80\n",
        "CONFERENCE_HOURS_EXTRA = 24  # spread throughout year\n",
        "\n",
        "# Coverage constraints\n",
        "MIN_SPECIALISTS_PER_WEEK = 2  # Minimum specialists working simultaneously\n",
        "MIN_COVERAGE_PER_SUBSPEC = 1  # Minimum specialists per subspecialism per week\n",
        "MAX_LEAVE_PERCENTAGE = 0.4  # Max 40% of specialists can be on leave\n",
        "\n",
        "# Session constraints (from assignment)\n",
        "OPD_SESSION_SIZES = [2, 4, 6, 8]  # hours\n",
        "OR_SESSION_MULTIPLE = 0.5  # 30-minute multiples\n",
        "\n",
        "# Choose which Part D solution to use\n",
        "USE_SLACK_SOLUTION = True\n",
        "SLACK_PCT = 0.20\n",
        "\n",
        "# ---------- RE-RUN PART D LOGIC ----------\n",
        "print(\"=\" * 60)\n",
        "print(\"PART E1 IMPROVED: Re-solving Part D to extract assignments\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Helper functions (same as before)\n",
        "def count_weekdays_in_span(start_weekday: int, length_days: int) -> int:\n",
        "    if length_days <= 0:\n",
        "        return 0\n",
        "    full_weeks, rem = divmod(length_days, 7)\n",
        "    base = full_weeks * 5\n",
        "    cnt = sum(1 for i in range(rem) if (start_weekday + i) % 7 < 5)\n",
        "    return base + cnt\n",
        "\n",
        "def avg_weekdays_over_weekday_starts(length_days: int) -> float:\n",
        "    if length_days <= 0:\n",
        "        return 0.0\n",
        "    vals = [count_weekdays_in_span(wd, length_days) for wd in range(5)]\n",
        "    return np.mean(vals)\n",
        "\n",
        "def coerce_numeric(df: pd.DataFrame):\n",
        "    for c in df.columns:\n",
        "        try:\n",
        "            df[c] = pd.to_numeric(df[c], errors='ignore')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "def round_to_sessions(hours, session_sizes):\n",
        "    \"\"\"Round hours to nearest valid session size\"\"\"\n",
        "    if hours < 0.5:\n",
        "        return 0\n",
        "    closest = min(session_sizes, key=lambda x: abs(x - hours))\n",
        "    return closest\n",
        "\n",
        "def round_to_multiple(hours, multiple):\n",
        "    \"\"\"Round to nearest multiple (e.g., 0.5 for OR sessions)\"\"\"\n",
        "    if hours < multiple / 2:\n",
        "        return 0\n",
        "    return round(hours / multiple) * multiple\n",
        "\n",
        "# Load data\n",
        "START_H, END_H = 1040, 3120\n",
        "SIM_START_WEEKDAY = 0\n",
        "\n",
        "xls = pd.ExcelFile(DATA_PATH)\n",
        "patients = pd.read_excel(xls, \"Patients\")\n",
        "squeue = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los = pd.read_excel(xls, \"surgeryLOS\")\n",
        "specialist = pd.read_excel(xls, sheet_name=\"specialist\", header=None)\n",
        "\n",
        "for df in [patients, squeue, surg_los, in_ward]:\n",
        "    coerce_numeric(df)\n",
        "\n",
        "if 'subsub' in surg_los.columns and 'subsubsp' not in surg_los.columns:\n",
        "    surg_los = surg_los.rename(columns={'subsub': 'subsubsp'})\n",
        "\n",
        "# Compute demand (same as Part D)\n",
        "patients['arrival (h)'] = pd.to_numeric(patients['arrival (h)'], errors='coerce')\n",
        "patients['timeod (min)'] = pd.to_numeric(patients['timeod (min)'], errors='coerce')\n",
        "patients['subspec'] = pd.to_numeric(patients['subspec'], errors='coerce')\n",
        "\n",
        "opd_year = patients[patients['arrival (h)'] <= END_H].copy()\n",
        "opd_by_sub_min = opd_year.groupby('subspec', dropna=True)['timeod (min)'].sum().rename('OPD minutes').reset_index()\n",
        "\n",
        "squeue['subspec'] = pd.to_numeric(squeue['subspec'], errors='coerce')\n",
        "squeue['subsubsp'] = pd.to_numeric(squeue['subsubsp'], errors='coerce')\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "\n",
        "map_cols = ['subspec', 'subsubsp', 'surgery time(min)', 'LOS(DAYS)']\n",
        "surg_map = surg_los[[c for c in map_cols if c in surg_los.columns]].drop_duplicates()\n",
        "surg_year = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_m = surg_year.merge(surg_map, on=['subspec', 'subsubsp'], how='left')\n",
        "\n",
        "or_by_sub_min = surg_m.groupby('subspec', dropna=True)['surgery time(min)'].sum(min_count=1).fillna(0).rename('OR minutes').reset_index() if 'surgery time(min)' in surg_m.columns else pd.DataFrame({'subspec': [], 'OR minutes': []})\n",
        "\n",
        "in_ward['subspec'] = pd.to_numeric(in_ward['subspec'], errors='coerce')\n",
        "in_ward['remaining LOS'] = pd.to_numeric(in_ward['remaining LOS'], errors='coerce').fillna(0).astype(int)\n",
        "in_ward['ward_days_initial'] = in_ward['remaining LOS'] + 1\n",
        "in_ward['weekday_visits_initial'] = in_ward['ward_days_initial'].apply(lambda k: count_weekdays_in_span(SIM_START_WEEKDAY, k))\n",
        "in_ward['Ward minutes (initial)'] = 15 * in_ward['weekday_visits_initial']\n",
        "ward_init_by_sub_min = in_ward.groupby('subspec', dropna=True)['Ward minutes (initial)'].sum().reset_index()\n",
        "\n",
        "if 'LOS(DAYS)' in surg_m.columns:\n",
        "    surg_m['LOS(DAYS)'] = pd.to_numeric(surg_m['LOS(DAYS)'], errors='coerce').fillna(0).astype(int)\n",
        "    surg_m['ward_days_postop'] = surg_m['LOS(DAYS)'] + 1\n",
        "    surg_m['weekday_visits_postop'] = surg_m['ward_days_postop'].apply(avg_weekdays_over_weekday_starts)\n",
        "    surg_m['Ward minutes (post-op)'] = 15 * surg_m['weekday_visits_postop']\n",
        "    ward_postop_by_sub_min = surg_m.groupby('subspec', dropna=True)['Ward minutes (post-op)'].sum().reset_index()\n",
        "else:\n",
        "    ward_postop_by_sub_min = pd.DataFrame({'subspec': [], 'Ward minutes (post-op)': []})\n",
        "\n",
        "opd_counts = opd_year.groupby('subspec', dropna=True).size().rename('OPD count').reset_index()\n",
        "surg_counts = surg_m.groupby('subspec', dropna=True).size().rename('Surgery count').reset_index()\n",
        "admin_opd_by_sub = opd_counts.assign(admin_minutes_opd=lambda d: d['OPD count'] * 5)[['subspec', 'admin_minutes_opd']]\n",
        "admin_surg_by_sub = surg_counts.assign(admin_minutes_surg=lambda d: d['Surgery count'] * 10)[['subspec', 'admin_minutes_surg']]\n",
        "\n",
        "dfs = [opd_by_sub_min, or_by_sub_min, ward_postop_by_sub_min, ward_init_by_sub_min, admin_opd_by_sub, admin_surg_by_sub]\n",
        "per_sub = reduce(lambda L, R: L.merge(R, on='subspec', how='outer'), dfs).fillna(0)\n",
        "\n",
        "per_sub['OPD hours'] = per_sub['OPD minutes'] / 60.0\n",
        "per_sub['OR hours'] = per_sub['OR minutes'] / 60.0\n",
        "per_sub['Ward hours'] = (per_sub.get('Ward minutes (post-op)', 0) + per_sub.get('Ward minutes (initial)', 0)) / 60.0\n",
        "per_sub['Admin hours'] = (per_sub.get('admin_minutes_opd', 0) + per_sub.get('admin_minutes_surg', 0)) / 60.0\n",
        "per_sub_table = per_sub[['subspec', 'OPD hours', 'OR hours', 'Ward hours', 'Admin hours']].sort_values('subspec').reset_index(drop=True)\n",
        "\n",
        "task_types = ['OPD', 'OR', 'Ward', 'Admin']\n",
        "subspecs = sorted(per_sub_table['subspec'].dropna().astype(int).unique().tolist())\n",
        "tasks = [(t, s) for s in subspecs for t in task_types]\n",
        "\n",
        "demand_base = {}\n",
        "for (t, s) in tasks:\n",
        "    row = per_sub_table[per_sub_table['subspec'] == s]\n",
        "    demand_base[(t, s)] = float(row[f\"{t} hours\"].iloc[0]) if not row.empty else 0.0\n",
        "\n",
        "# Parse specialist data\n",
        "spec_raw = specialist.fillna(\"\").astype(str)\n",
        "\n",
        "fte_row_idx = None\n",
        "for r in range(spec_raw.shape[0]):\n",
        "    row_tokens = \" \".join([str(x).strip().lower() for x in spec_raw.iloc[r, :].tolist()]).split()\n",
        "    if \"fte\" in row_tokens:\n",
        "        fte_row_idx = r\n",
        "        break\n",
        "\n",
        "FTE = []\n",
        "num_specialists = None\n",
        "if fte_row_idx is not None:\n",
        "    for c in range(spec_raw.shape[1]):\n",
        "        try:\n",
        "            v = float(spec_raw.iat[fte_row_idx, c])\n",
        "            if 0 <= v <= 2.5:\n",
        "                FTE.append(v)\n",
        "        except:\n",
        "            pass\n",
        "    num_specialists = len(FTE)\n",
        "    candidate_cols = list(range(2, 2 + num_specialists))\n",
        "else:\n",
        "    num_specialists = 15\n",
        "    FTE = [1.0] * num_specialists\n",
        "    candidate_cols = list(range(2, 2 + num_specialists))\n",
        "\n",
        "num_subspec = 10\n",
        "skill_rows = []\n",
        "for r in range(min(40, spec_raw.shape[0])):\n",
        "    flags = []\n",
        "    for c in candidate_cols[:num_specialists]:\n",
        "        val = spec_raw.iat[r, c].strip()\n",
        "        if val in (\"0\", \"1\", \"0.0\", \"1.0\"):\n",
        "            flags.append(1)\n",
        "        else:\n",
        "            try:\n",
        "                num = float(val)\n",
        "                flags.append(1 if int(num) in (0, 1) else 0)\n",
        "            except:\n",
        "                flags.append(0)\n",
        "    if sum(flags) >= max(3, len(candidate_cols) // 2):\n",
        "        skill_rows.append(r)\n",
        "\n",
        "if len(skill_rows) >= 10:\n",
        "    skill_rows = skill_rows[:10]\n",
        "\n",
        "S = {(i, s): 0 for i in range(num_specialists) for s in range(1, num_subspec + 1)}\n",
        "if skill_rows:\n",
        "    for s_idx, r in enumerate(skill_rows):\n",
        "        if s_idx >= num_subspec:\n",
        "            break\n",
        "        for i, c in enumerate(candidate_cols[:num_specialists]):\n",
        "            try:\n",
        "                val = spec_raw.iat[r, c].strip()\n",
        "                if val in (\"1\", \"1.0\", \"1.00\"):\n",
        "                    S[(i, s_idx + 1)] = 1\n",
        "                else:\n",
        "                    nv = float(val)\n",
        "                    S[(i, s_idx + 1)] = 1 if int(nv) == 1 else 0\n",
        "            except:\n",
        "                S[(i, s_idx + 1)] = 0\n",
        "else:\n",
        "    for i in range(num_specialists):\n",
        "        for s in range(1, num_subspec + 1):\n",
        "            S[(i, s)] = 1\n",
        "\n",
        "if len(FTE) < num_specialists:\n",
        "    FTE = FTE + [1.0] * (num_specialists - len(FTE))\n",
        "elif len(FTE) > num_specialists:\n",
        "    FTE = FTE[:num_specialists]\n",
        "FTE = [float(x) for x in FTE]\n",
        "\n",
        "# Parse preferences\n",
        "specialist_preferences = {}\n",
        "for i in range(num_specialists):\n",
        "    prefs = []\n",
        "    col = candidate_cols[i]\n",
        "\n",
        "    for r in range(spec_raw.shape[0]):\n",
        "        try:\n",
        "            val = spec_raw.iat[r, col].strip()\n",
        "            week_num = int(float(val))\n",
        "            if 1 <= week_num <= 52:\n",
        "                point = 1\n",
        "                row_label = \" \".join([str(spec_raw.iat[r, 0]), str(spec_raw.iat[r, 1])]).lower()\n",
        "                if \"pref\" in row_label or \"holiday\" in row_label or \"conference\" in row_label:\n",
        "                    if r + 1 < spec_raw.shape[0]:\n",
        "                        try:\n",
        "                            point = int(float(spec_raw.iat[r + 1, col]))\n",
        "                        except:\n",
        "                            pass\n",
        "                    prefs.append((week_num - 1, point))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(prefs) < 10:\n",
        "        np.random.seed(i)\n",
        "        remaining = 10 - len(prefs)\n",
        "        used_weeks = set([w for w, p in prefs])\n",
        "        available_weeks = [w for w in range(WEEKS) if w not in used_weeks]\n",
        "        for _ in range(remaining):\n",
        "            if available_weeks:\n",
        "                w = np.random.choice(available_weeks)\n",
        "                available_weeks.remove(w)\n",
        "                prefs.append((w, 1))\n",
        "\n",
        "    specialist_preferences[i] = prefs[:10]\n",
        "\n",
        "print(f\"✓ Parsed {num_specialists} specialists\")\n",
        "print(f\"✓ FTE values: {FTE}\")\n",
        "\n",
        "# ---------- SOLVE PART D MILP ----------\n",
        "RESERVED_PER_HIRED = 8 * 5 * 8 + 2 * 5 * 8 + 24 + 80\n",
        "X_UPPER_IF_HIRED = 1600\n",
        "\n",
        "slack_to_use = SLACK_PCT if USE_SLACK_SOLUTION else 0.0\n",
        "req = {k: v * (1.0 + slack_to_use) for k, v in demand_base.items()}\n",
        "\n",
        "prob = pulp.LpProblem(\"PartE1_ResolveD\", pulp.LpMinimize)\n",
        "\n",
        "X = {}\n",
        "for i in range(num_specialists):\n",
        "    for (t, s) in tasks:\n",
        "        X[(i, t, s)] = pulp.LpVariable(f\"X_{i}_{t}_{s}\", lowBound=0, cat='Continuous')\n",
        "\n",
        "Z = {i: pulp.LpVariable(f\"Z_{i}\", cat='Binary') for i in range(num_specialists)}\n",
        "\n",
        "prob += pulp.lpSum([FTE[i] * Z[i] for i in range(num_specialists)])\n",
        "\n",
        "for (t, s) in tasks:\n",
        "    prob += pulp.lpSum([X[(i, t, s)] for i in range(num_specialists)]) >= req.get((t, s), 0.0)\n",
        "\n",
        "for i in range(num_specialists):\n",
        "    for (t, s) in tasks:\n",
        "        if S.get((i, s), 0) == 0:\n",
        "            prob += X[(i, t, s)] == 0\n",
        "        prob += X[(i, t, s)] <= X_UPPER_IF_HIRED * Z[i]\n",
        "\n",
        "for i in range(num_specialists):\n",
        "    cap_i = 52 * 40 * FTE[i]\n",
        "    available_i = max(0.0, cap_i - RESERVED_PER_HIRED)\n",
        "    prob += pulp.lpSum([X[(i, t, s)] for (t, s) in tasks]) <= available_i * Z[i]\n",
        "\n",
        "print(f\"\\n✓ Solving Part D MILP with {slack_to_use*100:.0f}% slack...\")\n",
        "solver = pulp.PULP_CBC_CMD(msg=0, timeLimit=300, threads=2)\n",
        "prob.solve(solver)\n",
        "\n",
        "Z_vals = {i: int(round(pulp.value(Z[i]) if pulp.value(Z[i]) else 0)) for i in range(num_specialists)}\n",
        "hired_specialists = [i for i, z in Z_vals.items() if z == 1]\n",
        "\n",
        "print(f\"✓ Hired specialists: {hired_specialists}\")\n",
        "print(f\"✓ Total hired: {len(hired_specialists)}\")\n",
        "\n",
        "# Extract X values\n",
        "X_assignments = []\n",
        "for i in hired_specialists:\n",
        "    for (t, s) in tasks:\n",
        "        val = pulp.value(X[(i, t, s)])\n",
        "        if val and val > 0.01:\n",
        "            X_assignments.append({\n",
        "                'specialist': i,\n",
        "                'task': t,\n",
        "                'subspec': s,\n",
        "                'assigned_h': val\n",
        "            })\n",
        "\n",
        "partD_assignments = pd.DataFrame(X_assignments)\n",
        "print(f\"✓ Extracted {len(partD_assignments)} non-zero assignments\")\n",
        "\n",
        "# ---------- E1: IMPROVED WEEKLY SCHEDULE CONSTRUCTION ----------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PART E1 IMPROVED: Building Weekly Schedule with Coverage\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Track leave assignments for coverage checking\n",
        "leave_tracker = {w: [] for w in range(WEEKS)}  # week -> list of specialists on leave\n",
        "subspec_coverage = {(w, s): [] for w in range(WEEKS) for s in subspecs}  # (week, subspec) -> working specialists\n",
        "\n",
        "weekly_schedule = []\n",
        "\n",
        "# ---------- PHASE 1: COORDINATED LEAVE ALLOCATION ----------\n",
        "print(\"\\n--- Phase 1: Allocating Leave with Coverage Constraints ---\")\n",
        "\n",
        "# Build preference priority queue (all specialists combined)\n",
        "all_prefs = []\n",
        "for i in hired_specialists:\n",
        "    prefs = specialist_preferences.get(i, [])\n",
        "    for w, p in prefs:\n",
        "        all_prefs.append((i, w, p))\n",
        "\n",
        "# Sort by preference points (descending), then by specialist ID (for determinism)\n",
        "all_prefs_sorted = sorted(all_prefs, key=lambda x: (-x[2], x[0]))\n",
        "\n",
        "# Track assigned leave per specialist\n",
        "specialist_holiday_weeks = {i: [] for i in hired_specialists}\n",
        "specialist_conference_weeks = {i: [] for i in hired_specialists}\n",
        "\n",
        "# Allocate holidays (8 weeks per specialist)\n",
        "print(\"Allocating holidays...\")\n",
        "for specialist_id, week, points in all_prefs_sorted:\n",
        "    if len(specialist_holiday_weeks[specialist_id]) >= HOLIDAY_WEEKS_REQUIRED:\n",
        "        continue  # This specialist already has 8 holiday weeks\n",
        "\n",
        "    # Check coverage constraints\n",
        "    current_leave_count = len(leave_tracker[week])\n",
        "    max_allowed_leave = max(1, int(len(hired_specialists) * MAX_LEAVE_PERCENTAGE))\n",
        "\n",
        "    if current_leave_count >= max_allowed_leave:\n",
        "        continue  # Too many people already off this week\n",
        "\n",
        "    # Check if assigning this leave would violate minimum working staff\n",
        "    if (len(hired_specialists) - current_leave_count - 1) < MIN_SPECIALISTS_PER_WEEK:\n",
        "        continue  # Would leave too few specialists working\n",
        "\n",
        "    # Check subspecialism coverage\n",
        "    can_assign = True\n",
        "    for s in subspecs:\n",
        "        if S.get((specialist_id, s), 0) == 1:  # This specialist is skilled in subspec s\n",
        "            # Count how many OTHER skilled specialists would still be working\n",
        "            skilled_working = sum(1 for other in hired_specialists\n",
        "                                 if other != specialist_id\n",
        "                                 and other not in leave_tracker[week]\n",
        "                                 and S.get((other, s), 0) == 1)\n",
        "            if skilled_working < MIN_COVERAGE_PER_SUBSPEC:\n",
        "                can_assign = False\n",
        "                break\n",
        "\n",
        "    if not can_assign:\n",
        "        continue  # Would violate subspecialism coverage\n",
        "\n",
        "    # All constraints satisfied - assign this week\n",
        "    specialist_holiday_weeks[specialist_id].append(week)\n",
        "    leave_tracker[week].append(specialist_id)\n",
        "\n",
        "# Fill remaining holiday weeks if needed (fallback to any available week)\n",
        "print(\"Filling remaining holiday slots...\")\n",
        "for i in hired_specialists:\n",
        "    while len(specialist_holiday_weeks[i]) < HOLIDAY_WEEKS_REQUIRED:\n",
        "        # Find least-loaded week that satisfies constraints\n",
        "        best_week = None\n",
        "        min_load = float('inf')\n",
        "\n",
        "        for w in range(WEEKS):\n",
        "            if w in specialist_holiday_weeks[i]:\n",
        "                continue  # Already assigned\n",
        "\n",
        "            current_load = len(leave_tracker[w])\n",
        "            max_allowed = max(1, int(len(hired_specialists) * MAX_LEAVE_PERCENTAGE))\n",
        "\n",
        "            if current_load >= max_allowed:\n",
        "                continue\n",
        "\n",
        "            if (len(hired_specialists) - current_load - 1) < MIN_SPECIALISTS_PER_WEEK:\n",
        "                continue\n",
        "\n",
        "            # Check subspec coverage\n",
        "            valid = True\n",
        "            for s in subspecs:\n",
        "                if S.get((i, s), 0) == 1:\n",
        "                    skilled_working = sum(1 for other in hired_specialists\n",
        "                                         if other != i\n",
        "                                         and other not in leave_tracker[w]\n",
        "                                         and S.get((other, s), 0) == 1)\n",
        "                    if skilled_working < MIN_COVERAGE_PER_SUBSPEC:\n",
        "                        valid = False\n",
        "                        break\n",
        "\n",
        "            if valid and current_load < min_load:\n",
        "                best_week = w\n",
        "                min_load = current_load\n",
        "\n",
        "        if best_week is not None:\n",
        "            specialist_holiday_weeks[i].append(best_week)\n",
        "            leave_tracker[best_week].append(i)\n",
        "        else:\n",
        "            # Fallback: just find ANY week (should rarely happen)\n",
        "            for w in range(WEEKS):\n",
        "                if w not in specialist_holiday_weeks[i]:\n",
        "                    specialist_holiday_weeks[i].append(w)\n",
        "                    leave_tracker[w].append(i)\n",
        "                    break\n",
        "\n",
        "# Allocate conference weeks (2 weeks per specialist, similar logic)\n",
        "print(\"Allocating conference weeks...\")\n",
        "remaining_prefs = [(i, w, p) for i, w, p in all_prefs_sorted\n",
        "                   if w not in specialist_holiday_weeks.get(i, [])]\n",
        "\n",
        "for specialist_id, week, points in remaining_prefs:\n",
        "    if len(specialist_conference_weeks[specialist_id]) >= CONFERENCE_WEEKS:\n",
        "        continue\n",
        "\n",
        "    if week in specialist_holiday_weeks[specialist_id]:\n",
        "        continue  # Already used for holiday\n",
        "\n",
        "    # Same coverage checks\n",
        "    current_leave_count = len(leave_tracker[week])\n",
        "    max_allowed_leave = max(1, int(len(hired_specialists) * MAX_LEAVE_PERCENTAGE))\n",
        "\n",
        "    if current_leave_count >= max_allowed_leave:\n",
        "        continue\n",
        "\n",
        "    if (len(hired_specialists) - current_leave_count - 1) < MIN_SPECIALISTS_PER_WEEK:\n",
        "        continue\n",
        "\n",
        "    can_assign = True\n",
        "    for s in subspecs:\n",
        "        if S.get((specialist_id, s), 0) == 1:\n",
        "            skilled_working = sum(1 for other in hired_specialists\n",
        "                                 if other != specialist_id\n",
        "                                 and other not in leave_tracker[week]\n",
        "                                 and S.get((other, s), 0) == 1)\n",
        "            if skilled_working < MIN_COVERAGE_PER_SUBSPEC:\n",
        "                can_assign = False\n",
        "                break\n",
        "\n",
        "    if can_assign:\n",
        "        specialist_conference_weeks[specialist_id].append(week)\n",
        "        leave_tracker[week].append(specialist_id)\n",
        "\n",
        "# Fill remaining conference weeks\n",
        "print(\"Filling remaining conference slots...\")\n",
        "for i in hired_specialists:\n",
        "    while len(specialist_conference_weeks[i]) < CONFERENCE_WEEKS:\n",
        "        best_week = None\n",
        "        min_load = float('inf')\n",
        "\n",
        "        for w in range(WEEKS):\n",
        "            if w in specialist_holiday_weeks[i] or w in specialist_conference_weeks[i]:\n",
        "                continue\n",
        "\n",
        "            current_load = len(leave_tracker[w])\n",
        "            max_allowed = max(1, int(len(hired_specialists) * MAX_LEAVE_PERCENTAGE))\n",
        "\n",
        "            if current_load >= max_allowed:\n",
        "                continue\n",
        "\n",
        "            if (len(hired_specialists) - current_load - 1) < MIN_SPECIALISTS_PER_WEEK:\n",
        "                continue\n",
        "\n",
        "            valid = True\n",
        "            for s in subspecs:\n",
        "                if S.get((i, s), 0) == 1:\n",
        "                    skilled_working = sum(1 for other in hired_specialists\n",
        "                                         if other != i\n",
        "                                         and other not in leave_tracker[w]\n",
        "                                         and S.get((other, s), 0) == 1)\n",
        "                    if skilled_working < MIN_COVERAGE_PER_SUBSPEC:\n",
        "                        valid = False\n",
        "                        break\n",
        "\n",
        "            if valid and current_load < min_load:\n",
        "                best_week = w\n",
        "                min_load = current_load\n",
        "\n",
        "        if best_week is not None:\n",
        "            specialist_conference_weeks[i].append(best_week)\n",
        "            leave_tracker[best_week].append(i)\n",
        "        else:\n",
        "            for w in range(WEEKS):\n",
        "                if w not in specialist_holiday_weeks[i] and w not in specialist_conference_weeks[i]:\n",
        "                    specialist_conference_weeks[i].append(w)\n",
        "                    leave_tracker[w].append(i)\n",
        "                    break\n",
        "\n",
        "print(\"✓ Leave allocation complete with coverage constraints\")\n",
        "\n",
        "# ---------- PHASE 2: DISTRIBUTE CLINICAL HOURS CORRECTLY ----------\n",
        "print(\"\\n--- Phase 2: Distributing Clinical Work ---\")\n",
        "\n",
        "for i in hired_specialists:\n",
        "    fte = FTE[i]\n",
        "\n",
        "    # Get Part D clinical assignments\n",
        "    spec_tasks = partD_assignments[partD_assignments['specialist'] == i].copy()\n",
        "\n",
        "    if spec_tasks.empty:\n",
        "        continue\n",
        "\n",
        "    # Calculate working weeks\n",
        "    holiday_weeks = specialist_holiday_weeks[i]\n",
        "    conference_weeks = specialist_conference_weeks[i]\n",
        "    leave_weeks = set(holiday_weeks + conference_weeks)\n",
        "    working_weeks = [w for w in range(WEEKS) if w not in leave_weeks]\n",
        "    num_working_weeks = len(working_weeks)\n",
        "\n",
        "    if num_working_weeks == 0:\n",
        "        continue\n",
        "\n",
        "    # Calculate per-week education and conference spread\n",
        "    education_total = EDUCATION_HOURS_YEAR * fte\n",
        "    conference_spread_total = CONFERENCE_HOURS_EXTRA * fte\n",
        "\n",
        "    edu_per_week = education_total / num_working_weeks\n",
        "    conf_spread_per_week = conference_spread_total / num_working_weeks\n",
        "\n",
        "    # Calculate clinical hours per working week\n",
        "    hours_per_working_week = HOURS_PER_WEEK * fte\n",
        "    clinical_per_week = hours_per_working_week - edu_per_week - conf_spread_per_week\n",
        "\n",
        "    # FIXED: Calculate weekly clinical hours based on Part D annual totals\n",
        "    total_clinical_annual = spec_tasks['assigned_h'].sum()\n",
        "\n",
        "    # Build weekly schedule\n",
        "    for w in range(WEEKS):\n",
        "        if w in holiday_weeks:\n",
        "            weekly_schedule.append({\n",
        "                'week': w,\n",
        "                'specialist': i,\n",
        "                'task': 'Holiday',\n",
        "                'subspec': None,\n",
        "                'hours': HOURS_PER_WEEK * fte\n",
        "            })\n",
        "        elif w in conference_weeks:\n",
        "            weekly_schedule.append({\n",
        "                'week': w,\n",
        "                'specialist': i,\n",
        "                'task': 'Conference',\n",
        "                'subspec': None,\n",
        "                'hours': HOURS_PER_WEEK * fte\n",
        "            })\n",
        "        else:\n",
        "            # Working week\n",
        "            # Add education\n",
        "            if edu_per_week > 0.01:\n",
        "                weekly_schedule.append({\n",
        "                    'week': w,\n",
        "                    'specialist': i,\n",
        "                    'task': 'Education',\n",
        "                    'subspec': None,\n",
        "                    'hours': edu_per_week\n",
        "                })\n",
        "\n",
        "            # Add conference spread\n",
        "            if conf_spread_per_week > 0.01:\n",
        "                weekly_schedule.append({\n",
        "                    'week': w,\n",
        "                    'specialist': i,\n",
        "                    'task': 'Conference_Spread',\n",
        "                    'subspec': None,\n",
        "                    'hours': conf_spread_per_week\n",
        "                })\n",
        "\n",
        "            # Distribute clinical work proportionally\n",
        "            # Key fix: Use total_clinical_annual / num_working_weeks as base\n",
        "            clinical_budget_this_week = total_clinical_annual / num_working_weeks\n",
        "\n",
        "            for _, row in spec_tasks.iterrows():\n",
        "                task = row['task']\n",
        "                subspec = int(row['subspec'])\n",
        "                annual_target = row['assigned_h']\n",
        "\n",
        "                # This task's share this week\n",
        "                task_hours_this_week = annual_target / num_working_weeks\n",
        "\n",
        "                # Apply session rounding for OPD and OR\n",
        "                if task == 'OPD':\n",
        "                    task_hours_this_week = round_to_sessions(task_hours_this_week, OPD_SESSION_SIZES)\n",
        "                elif task == 'OR':\n",
        "                    task_hours_this_week = round_to_multiple(task_hours_this_week, OR_SESSION_MULTIPLE)\n",
        "\n",
        "                if task_hours_this_week > 0.01:\n",
        "                    weekly_schedule.append({\n",
        "                        'week': w,\n",
        "                        'specialist': i,\n",
        "                        'task': task,\n",
        "                        'subspec': subspec,\n",
        "                        'hours': task_hours_this_week\n",
        "                    })\n",
        "\n",
        "weekly_schedule_df = pd.DataFrame(weekly_schedule)\n",
        "\n",
        "# ---------- CALCULATE PREFERENCE SATISFACTION ----------\n",
        "print(\"\\n--- Calculating Preference Satisfaction ---\")\n",
        "\n",
        "total_pref_points = 0\n",
        "honored_pref_points = 0\n",
        "\n",
        "for i in hired_specialists:\n",
        "    prefs = specialist_preferences.get(i, [])\n",
        "    total_pref_points += sum(p for w, p in prefs)\n",
        "\n",
        "    assigned_leave_weeks = set(specialist_holiday_weeks[i] + specialist_conference_weeks[i])\n",
        "\n",
        "    pref_dict = dict(prefs)\n",
        "    honored_pref_points += sum(pref_dict.get(w, 0) for w in assigned_leave_weeks if w in pref_dict)\n",
        "\n",
        "pref_satisfaction_score = (honored_pref_points / total_pref_points * 100) if total_pref_points > 0 else 0\n",
        "\n",
        "# ---------- COVERAGE ANALYSIS ----------\n",
        "print(\"\\n--- Analyzing Coverage ---\")\n",
        "\n",
        "coverage_issues = []\n",
        "for w in range(WEEKS):\n",
        "    on_leave = leave_tracker[w]\n",
        "    working = [i for i in hired_specialists if i not in on_leave]\n",
        "\n",
        "    if len(working) < MIN_SPECIALISTS_PER_WEEK:\n",
        "        coverage_issues.append(f\"Week {w}: Only {len(working)} specialists working (min={MIN_SPECIALISTS_PER_WEEK})\")\n",
        "\n",
        "    # Check subspecialism coverage\n",
        "    for s in subspecs:\n",
        "        skilled_working = [i for i in working if S.get((i, s), 0) == 1]\n",
        "        if len(skilled_working) < MIN_COVERAGE_PER_SUBSPEC:\n",
        "            coverage_issues.append(f\"Week {w}, Subspec {s}: Only {len(skilled_working)} skilled specialists working\")\n",
        "\n",
        "if coverage_issues:\n",
        "    print(f\"⚠ Found {len(coverage_issues)} coverage issues:\")\n",
        "    for issue in coverage_issues[:10]:  # Show first 10\n",
        "        print(f\"  • {issue}\")\n",
        "    if len(coverage_issues) > 10:\n",
        "        print(f\"  ... and {len(coverage_issues) - 10} more issues\")\n",
        "else:\n",
        "    print(\"✓ All weeks meet minimum coverage requirements\")\n",
        "\n",
        "# ---------- VERIFICATION ----------\n",
        "print(\"\\n--- Verification ---\")\n",
        "\n",
        "# Verify total hours per specialist\n",
        "print(\"\\n=== Total Hours per Specialist ===\")\n",
        "verification_results = []\n",
        "for i in hired_specialists:\n",
        "    spec_total = weekly_schedule_df[weekly_schedule_df['specialist'] == i]['hours'].sum()\n",
        "    expected = WEEKS * HOURS_PER_WEEK * FTE[i]\n",
        "    diff = abs(spec_total - expected)\n",
        "    status = \"✓\" if diff < 1 else \"⚠\"\n",
        "    verification_results.append({\n",
        "        'specialist': i,\n",
        "        'FTE': FTE[i],\n",
        "        'scheduled_h': spec_total,\n",
        "        'expected_h': expected,\n",
        "        'diff_h': diff,\n",
        "        'status': status\n",
        "    })\n",
        "    print(f\"{status} Specialist {i}: {spec_total:.1f}h vs {expected:.1f}h (diff: {diff:.1f}h)\")\n",
        "\n",
        "# Verify annual totals match Part D\n",
        "print(\"\\n=== Annual Task Totals vs Part D Targets ===\")\n",
        "task_verification = []\n",
        "for i in hired_specialists:\n",
        "    spec_tasks = partD_assignments[partD_assignments['specialist'] == i].copy()\n",
        "\n",
        "    for _, row in spec_tasks.iterrows():\n",
        "        task = row['task']\n",
        "        subspec = int(row['subspec'])\n",
        "        target = row['assigned_h']\n",
        "\n",
        "        # Calculate actual scheduled (excluding leave weeks)\n",
        "        scheduled = weekly_schedule_df[\n",
        "            (weekly_schedule_df['specialist'] == i) &\n",
        "            (weekly_schedule_df['task'] == task) &\n",
        "            (weekly_schedule_df['subspec'] == subspec)\n",
        "        ]['hours'].sum()\n",
        "\n",
        "        diff = abs(scheduled - target)\n",
        "        pct_diff = (diff / target * 100) if target > 0 else 0\n",
        "        status = \"✓\" if pct_diff < 5 else \"⚠\"  # Allow 5% deviation due to session rounding\n",
        "\n",
        "        task_verification.append({\n",
        "            'specialist': i,\n",
        "            'task': task,\n",
        "            'subspec': subspec,\n",
        "            'target_h': target,\n",
        "            'scheduled_h': scheduled,\n",
        "            'diff_h': diff,\n",
        "            'pct_diff': pct_diff,\n",
        "            'status': status\n",
        "        })\n",
        "\n",
        "        if pct_diff >= 5:\n",
        "            print(f\"{status} Spec {i}, {task} subspec {subspec}: {scheduled:.1f}h vs {target:.1f}h ({pct_diff:.1f}% diff)\")\n",
        "\n",
        "task_verification_df = pd.DataFrame(task_verification)\n",
        "large_deviations = task_verification_df[task_verification_df['pct_diff'] >= 5]\n",
        "if len(large_deviations) > 0:\n",
        "    print(f\"\\n⚠ {len(large_deviations)} task assignments have >5% deviation from Part D targets\")\n",
        "    print(\"  (This may be due to session rounding constraints)\")\n",
        "else:\n",
        "    print(\"\\n✓ All task assignments within 5% of Part D targets\")\n",
        "\n",
        "# ---------- OUTPUT SUMMARY ----------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Hired specialists: {len(hired_specialists)}\")\n",
        "print(f\"Total schedule entries: {len(weekly_schedule_df)}\")\n",
        "print(f\"\\nLeave allocation per specialist:\")\n",
        "print(f\"  • Holiday: {HOLIDAY_WEEKS_REQUIRED} weeks\")\n",
        "print(f\"  • Conference blocks: {CONFERENCE_WEEKS} weeks\")\n",
        "print(f\"  • Education: {EDUCATION_HOURS_YEAR}h/year (spread across working weeks)\")\n",
        "print(f\"  • Conference spread: {CONFERENCE_HOURS_EXTRA}h/year (spread across working weeks)\")\n",
        "print(f\"\\nCoverage constraints:\")\n",
        "print(f\"  • Min specialists per week: {MIN_SPECIALISTS_PER_WEEK}\")\n",
        "print(f\"  • Min per subspecialism: {MIN_COVERAGE_PER_SUBSPEC}\")\n",
        "print(f\"  • Max leave percentage: {MAX_LEAVE_PERCENTAGE*100:.0f}%\")\n",
        "print(f\"\\n✓ Preference satisfaction: {pref_satisfaction_score:.1f}%\")\n",
        "print(f\"  (Honored {honored_pref_points}/{total_pref_points} preference points)\")\n",
        "\n",
        "# Task summary\n",
        "task_summary = weekly_schedule_df.groupby(['specialist', 'task'])['hours'].sum().reset_index()\n",
        "task_pivot = task_summary.pivot(index='specialist', columns='task', values='hours').fillna(0)\n",
        "print(\"\\n=== Hours Summary by Specialist and Task ===\")\n",
        "print(task_pivot.to_string())\n",
        "\n",
        "# Weekly load analysis\n",
        "print(\"\\n=== Weekly Load Distribution ===\")\n",
        "weekly_load = []\n",
        "for w in range(WEEKS):\n",
        "    on_leave = len(leave_tracker[w])\n",
        "    working = len(hired_specialists) - on_leave\n",
        "    total_hours = weekly_schedule_df[\n",
        "        (weekly_schedule_df['week'] == w) &\n",
        "        (~weekly_schedule_df['task'].isin(['Holiday', 'Conference']))\n",
        "    ]['hours'].sum()\n",
        "    weekly_load.append({\n",
        "        'week': w,\n",
        "        'specialists_working': working,\n",
        "        'specialists_on_leave': on_leave,\n",
        "        'total_hours': total_hours\n",
        "    })\n",
        "\n",
        "weekly_load_df = pd.DataFrame(weekly_load)\n",
        "print(f\"Average specialists working per week: {weekly_load_df['specialists_working'].mean():.1f}\")\n",
        "print(f\"Min specialists working: {weekly_load_df['specialists_working'].min()} (week {weekly_load_df['specialists_working'].idxmin()})\")\n",
        "print(f\"Max specialists on leave: {weekly_load_df['specialists_on_leave'].max()} (week {weekly_load_df['specialists_on_leave'].idxmax()})\")\n",
        "\n",
        "# ---------- SAVE OUTPUTS ----------\n",
        "print(\"\\n--- Saving Outputs ---\")\n",
        "\n",
        "weekly_schedule_df.to_csv(\"PartE1_weekly_schedule_IMPROVED.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_weekly_schedule_IMPROVED.csv\")\n",
        "\n",
        "partD_assignments.to_csv(\"PartE1_partD_assignments_used.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_partD_assignments_used.csv\")\n",
        "\n",
        "# Preference details\n",
        "pref_details = []\n",
        "for i in hired_specialists:\n",
        "    prefs = specialist_preferences.get(i, [])\n",
        "    assigned_weeks = set(specialist_holiday_weeks[i] + specialist_conference_weeks[i])\n",
        "\n",
        "    pref_dict = dict(prefs)\n",
        "    for w, p in prefs:\n",
        "        pref_details.append({\n",
        "            'specialist': i,\n",
        "            'preferred_week': w,\n",
        "            'preference_points': p,\n",
        "            'honored': w in assigned_weeks,\n",
        "            'leave_type': 'Holiday' if w in specialist_holiday_weeks[i]\n",
        "                         else 'Conference' if w in specialist_conference_weeks[i]\n",
        "                         else None\n",
        "        })\n",
        "\n",
        "pref_df = pd.DataFrame(pref_details)\n",
        "pref_df.to_csv(\"PartE1_preference_satisfaction_IMPROVED.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_preference_satisfaction_IMPROVED.csv\")\n",
        "\n",
        "# Coverage analysis\n",
        "weekly_load_df.to_csv(\"PartE1_weekly_coverage_analysis.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_weekly_coverage_analysis.csv\")\n",
        "\n",
        "# Verification results\n",
        "verification_df = pd.DataFrame(verification_results)\n",
        "verification_df.to_csv(\"PartE1_specialist_verification.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_specialist_verification.csv\")\n",
        "\n",
        "task_verification_df.to_csv(\"PartE1_task_verification.csv\", index=False)\n",
        "print(\"✓ Saved: PartE1_task_verification.csv\")\n",
        "\n",
        "# Coverage issues log\n",
        "if coverage_issues:\n",
        "    with open(\"PartE1_coverage_issues.txt\", \"w\") as f:\n",
        "        f.write(\"COVERAGE ISSUES DETECTED\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "        for issue in coverage_issues:\n",
        "            f.write(issue + \"\\n\")\n",
        "    print(\"⚠ Saved: PartE1_coverage_issues.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAMPLE OUTPUT (first 50 rows)\")\n",
        "print(\"=\" * 60)\n",
        "print(weekly_schedule_df.head(50).to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecCt67BSbYyg",
        "outputId": "1b3c1cee-300f-4b30-ed62-e5cc7dc8aad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PART E1 IMPROVED: Re-solving Part D to extract assignments\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3243886940.py:60: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
            "  df[c] = pd.to_numeric(df[c], errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Parsed 15 specialists\n",
            "✓ FTE values: [1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6]\n",
            "\n",
            "✓ Solving Part D MILP with 20% slack...\n",
            "✓ Hired specialists: [0, 1, 2, 3, 4]\n",
            "✓ Total hired: 5\n",
            "✓ Extracted 44 non-zero assignments\n",
            "\n",
            "============================================================\n",
            "PART E1 IMPROVED: Building Weekly Schedule with Coverage\n",
            "============================================================\n",
            "\n",
            "--- Phase 1: Allocating Leave with Coverage Constraints ---\n",
            "Allocating holidays...\n",
            "Filling remaining holiday slots...\n",
            "Allocating conference weeks...\n",
            "Filling remaining conference slots...\n",
            "✓ Leave allocation complete with coverage constraints\n",
            "\n",
            "--- Phase 2: Distributing Clinical Work ---\n",
            "\n",
            "--- Calculating Preference Satisfaction ---\n",
            "\n",
            "--- Analyzing Coverage ---\n",
            "✓ All weeks meet minimum coverage requirements\n",
            "\n",
            "--- Verification ---\n",
            "\n",
            "=== Total Hours per Specialist ===\n",
            "⚠ Specialist 0: 1500.0h vs 2080.0h (diff: 580.0h)\n",
            "⚠ Specialist 1: 1804.7h vs 2080.0h (diff: 275.3h)\n",
            "⚠ Specialist 2: 2103.0h vs 2080.0h (diff: 23.0h)\n",
            "⚠ Specialist 3: 2045.1h vs 2080.0h (diff: 34.9h)\n",
            "⚠ Specialist 4: 1525.2h vs 1664.0h (diff: 138.8h)\n",
            "\n",
            "=== Annual Task Totals vs Part D Targets ===\n",
            "⚠ Spec 0, OPD subspec 1: 336.0h vs 936.6h (64.1% diff)\n",
            "⚠ Spec 0, OPD subspec 4: 336.0h vs 311.2h (8.0% diff)\n",
            "⚠ Spec 0, OR subspec 10: 42.0h vs 51.8h (18.9% diff)\n",
            "⚠ Spec 1, OPD subspec 2: 252.0h vs 274.1h (8.1% diff)\n",
            "⚠ Spec 1, OPD subspec 4: 336.0h vs 594.6h (43.5% diff)\n",
            "⚠ Spec 2, OR subspec 2: 105.0h vs 113.8h (7.7% diff)\n",
            "⚠ Spec 2, OPD subspec 9: 336.0h vs 305.9h (9.8% diff)\n",
            "⚠ Spec 2, OR subspec 9: 42.0h vs 45.6h (7.9% diff)\n",
            "⚠ Spec 3, OPD subspec 5: 84.0h vs 121.1h (30.6% diff)\n",
            "⚠ Spec 3, OR subspec 7: 21.0h vs 29.4h (28.6% diff)\n",
            "⚠ Spec 4, OPD subspec 3: 168.0h vs 129.7h (29.5% diff)\n",
            "⚠ Spec 4, OR subspec 8: 42.0h vs 51.8h (18.9% diff)\n",
            "⚠ Spec 4, OPD subspec 10: 336.0h vs 412.2h (18.5% diff)\n",
            "\n",
            "⚠ 13 task assignments have >5% deviation from Part D targets\n",
            "  (This may be due to session rounding constraints)\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "Hired specialists: 5\n",
            "Total schedule entries: 2318\n",
            "\n",
            "Leave allocation per specialist:\n",
            "  • Holiday: 8 weeks\n",
            "  • Conference blocks: 2 weeks\n",
            "  • Education: 80h/year (spread across working weeks)\n",
            "  • Conference spread: 24h/year (spread across working weeks)\n",
            "\n",
            "Coverage constraints:\n",
            "  • Min specialists per week: 2\n",
            "  • Min per subspecialism: 1\n",
            "  • Max leave percentage: 40%\n",
            "\n",
            "✓ Preference satisfaction: 98.7%\n",
            "  (Honored 442/448 preference points)\n",
            "\n",
            "=== Hours Summary by Specialist and Task ===\n",
            "task        Admin  Conference  Conference_Spread  Education  Holiday    OPD     OR   Ward\n",
            "specialist                                                                               \n",
            "0            3.58       80.00              24.00      80.00   320.00 672.00 252.00  68.46\n",
            "1          500.62       80.00              24.00      80.00   320.00 588.00 147.00  65.04\n",
            "2          695.68       80.00              24.00      80.00   320.00 504.00 378.00  21.30\n",
            "3          579.42       80.00              24.00      80.00   320.00 672.00  84.00 205.68\n",
            "4          258.88       64.00              19.20      64.00   256.00 756.00  42.00  65.10\n",
            "\n",
            "=== Weekly Load Distribution ===\n",
            "Average specialists working per week: 4.0\n",
            "Min specialists working: 3 (week 4)\n",
            "Max specialists on leave: 2 (week 4)\n",
            "\n",
            "--- Saving Outputs ---\n",
            "✓ Saved: PartE1_weekly_schedule_IMPROVED.csv\n",
            "✓ Saved: PartE1_partD_assignments_used.csv\n",
            "✓ Saved: PartE1_preference_satisfaction_IMPROVED.csv\n",
            "✓ Saved: PartE1_weekly_coverage_analysis.csv\n",
            "✓ Saved: PartE1_specialist_verification.csv\n",
            "✓ Saved: PartE1_task_verification.csv\n",
            "\n",
            "============================================================\n",
            "SAMPLE OUTPUT (first 50 rows)\n",
            "============================================================\n",
            " week  specialist              task  subspec  hours\n",
            "    0           0           Holiday      NaN  40.00\n",
            "    1           0         Education      NaN   1.90\n",
            "    1           0 Conference_Spread      NaN   0.57\n",
            "    1           0               OPD     1.00   8.00\n",
            "    1           0                OR     1.00   3.50\n",
            "    1           0              Ward     3.00   0.82\n",
            "    1           0               OPD     4.00   8.00\n",
            "    1           0                OR     5.00   1.50\n",
            "    1           0             Admin     5.00   0.09\n",
            "    1           0              Ward     7.00   0.24\n",
            "    1           0                OR    10.00   1.00\n",
            "    1           0              Ward    10.00   0.57\n",
            "    2           0         Education      NaN   1.90\n",
            "    2           0 Conference_Spread      NaN   0.57\n",
            "    2           0               OPD     1.00   8.00\n",
            "    2           0                OR     1.00   3.50\n",
            "    2           0              Ward     3.00   0.82\n",
            "    2           0               OPD     4.00   8.00\n",
            "    2           0                OR     5.00   1.50\n",
            "    2           0             Admin     5.00   0.09\n",
            "    2           0              Ward     7.00   0.24\n",
            "    2           0                OR    10.00   1.00\n",
            "    2           0              Ward    10.00   0.57\n",
            "    3           0         Education      NaN   1.90\n",
            "    3           0 Conference_Spread      NaN   0.57\n",
            "    3           0               OPD     1.00   8.00\n",
            "    3           0                OR     1.00   3.50\n",
            "    3           0              Ward     3.00   0.82\n",
            "    3           0               OPD     4.00   8.00\n",
            "    3           0                OR     5.00   1.50\n",
            "    3           0             Admin     5.00   0.09\n",
            "    3           0              Ward     7.00   0.24\n",
            "    3           0                OR    10.00   1.00\n",
            "    3           0              Ward    10.00   0.57\n",
            "    4           0           Holiday      NaN  40.00\n",
            "    5           0           Holiday      NaN  40.00\n",
            "    6           0         Education      NaN   1.90\n",
            "    6           0 Conference_Spread      NaN   0.57\n",
            "    6           0               OPD     1.00   8.00\n",
            "    6           0                OR     1.00   3.50\n",
            "    6           0              Ward     3.00   0.82\n",
            "    6           0               OPD     4.00   8.00\n",
            "    6           0                OR     5.00   1.50\n",
            "    6           0             Admin     5.00   0.09\n",
            "    6           0              Ward     7.00   0.24\n",
            "    6           0                OR    10.00   1.00\n",
            "    6           0              Ward    10.00   0.57\n",
            "    7           0         Education      NaN   1.90\n",
            "    7           0 Conference_Spread      NaN   0.57\n",
            "    7           0               OPD     1.00   8.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part E2\n"
      ],
      "metadata": {
        "id": "MoWCCEkBlr3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= Part E2 — Fixed Version with Critical Ward & Surgery Queue Fixes =======\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import deque, defaultdict\n",
        "import math, os\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "DATA_XLSX = \"Data for Assignment 7.xlsx\"\n",
        "E1_SCHEDULE_CSV = \"PartE1_weekly_schedule_IMPROVED.csv\"\n",
        "START_H = 1040\n",
        "END_H   = 3120\n",
        "WEEKS = 52\n",
        "HOURS_PER_WEEK_CAL = 24 * 7  # 168 hours/week\n",
        "\n",
        "# ---------- HELPERS ----------\n",
        "def hour_to_week(h):\n",
        "    return max(0, int(math.floor((h - START_H) / HOURS_PER_WEEK_CAL)))\n",
        "\n",
        "def minutes_to_hours(mins):\n",
        "    return float(mins) / 60.0\n",
        "\n",
        "def los_days_to_ward_hours(los_days):\n",
        "    return 0.25 * float(los_days)  # 15 min/day → 0.25 h/day\n",
        "\n",
        "# ---------- LOAD DATA ----------\n",
        "for fname in [DATA_XLSX, E1_SCHEDULE_CSV]:\n",
        "    if not os.path.exists(fname):\n",
        "        raise FileNotFoundError(f\"Missing required file: {fname}\")\n",
        "\n",
        "xls = pd.ExcelFile(DATA_XLSX)\n",
        "patients = pd.read_excel(xls, \"Patients\")\n",
        "squeue   = pd.read_excel(xls, \"Surgery Queue\")\n",
        "in_ward  = pd.read_excel(xls, \"In Ward\")\n",
        "surg_los = pd.read_excel(xls, \"surgeryLOS\")\n",
        "weekly_schedule = pd.read_csv(E1_SCHEDULE_CSV)\n",
        "\n",
        "# normalize schedule columns and types\n",
        "if 'subspec' not in weekly_schedule.columns:\n",
        "    weekly_schedule['subspec'] = weekly_schedule.get('subspecialism', None)\n",
        "weekly_schedule['hours'] = pd.to_numeric(weekly_schedule['hours'], errors='coerce').fillna(0.0)\n",
        "weekly_schedule['week']  = pd.to_numeric(weekly_schedule['week'], errors='coerce').fillna(0).astype(int)\n",
        "weekly_schedule['specialist'] = weekly_schedule['specialist'].astype(str)\n",
        "weekly_schedule['task'] = weekly_schedule['task'].astype(str)\n",
        "\n",
        "# VERIFY week indexing from E1 schedule\n",
        "week_values = weekly_schedule['week'].unique()\n",
        "min_week, max_week = week_values.min(), week_values.max()\n",
        "print(f\"✓ E1 schedule uses weeks {min_week} to {max_week}\")\n",
        "\n",
        "# Adjust if E1 uses 1-52 instead of 0-51\n",
        "if min_week == 1:\n",
        "    print(\"  → Adjusting to 0-indexed (subtracting 1 from all weeks)\")\n",
        "    weekly_schedule['week'] = weekly_schedule['week'] - 1\n",
        "\n",
        "specs_hired = sorted(weekly_schedule['specialist'].unique().tolist())\n",
        "\n",
        "# build capacity map from E1: (week, spec, task, subspec) -> hours\n",
        "spec_week_task_subspec_hours = defaultdict(float)\n",
        "for _, r in weekly_schedule.iterrows():\n",
        "    subs = int(r['subspec']) if (pd.notna(r['subspec']) and str(r['subspec']).strip()!='') else None\n",
        "    spec_week_task_subspec_hours[(int(r['week']), r['specialist'], r['task'], subs)] += float(r['hours'])\n",
        "\n",
        "# ---------- BUILD QUEUES ----------\n",
        "# OPD patients\n",
        "patients['arrival (h)'] = pd.to_numeric(patients['arrival (h)'], errors='coerce').fillna(START_H)\n",
        "patients['timeod (min)'] = pd.to_numeric(patients['timeod (min)'], errors='coerce').fillna(0)\n",
        "patients['subspec'] = pd.to_numeric(patients['subspec'], errors='coerce').fillna(1).astype(int)\n",
        "patients['arrival_week'] = patients['arrival (h)'].apply(hour_to_week)\n",
        "patients['timeod_h'] = patients['timeod (min)'].apply(minutes_to_hours)\n",
        "\n",
        "# OPD FIFO queues per subspec\n",
        "opd_queues = defaultdict(deque)\n",
        "for idx, row in patients.iterrows():\n",
        "    pid = row.get('patient_no', f\"p{idx}\")\n",
        "    opd_queues[int(row['subspec'])].append({\n",
        "        'patient_no': pid,\n",
        "        'arrival_week': int(row['arrival_week']),\n",
        "        'arrival_h': float(row['arrival (h)']),\n",
        "        'timeod_h': float(row['timeod_h']),\n",
        "        'subspec': int(row['subspec'])\n",
        "    })\n",
        "# ensure FIFO order\n",
        "for subs in list(opd_queues.keys()):\n",
        "    opd_queues[subs] = deque(sorted(list(opd_queues[subs]), key=lambda x: (x['arrival_week'], x['arrival_h'])))\n",
        "\n",
        "# Surgery queue\n",
        "squeue['due-date op (h)'] = pd.to_numeric(squeue['due-date op (h)'], errors='coerce')\n",
        "squeue['subspec'] = pd.to_numeric(squeue['subspec'], errors='coerce').fillna(1).astype(int)\n",
        "squeue['subsubsp'] = pd.to_numeric(squeue['subsubsp'], errors='coerce').fillna(0).astype(int)\n",
        "surg_in_window = squeue[(squeue['due-date op (h)'] >= START_H) & (squeue['due-date op (h)'] <= END_H)].copy()\n",
        "surg_in_window['due_week'] = surg_in_window['due-date op (h)'].apply(hour_to_week)\n",
        "\n",
        "surg_queues = defaultdict(deque)\n",
        "for idx, row in surg_in_window.iterrows():\n",
        "    pid = row.get('patient_no', f\"s{idx}\")\n",
        "    surg_queues[(int(row['subspec']), int(row['subsubsp']))].append({\n",
        "        'patient_no': pid,\n",
        "        'due_week': int(row['due_week']),\n",
        "        'subspec': int(row['subspec']),\n",
        "        'subsub': int(row['subsubsp'])\n",
        "    })\n",
        "# sort each surg queue by due_week\n",
        "for k in list(surg_queues.keys()):\n",
        "    surg_queues[k] = deque(sorted(list(surg_queues[k]), key=lambda x: (x['due_week'], x['patient_no'])))\n",
        "\n",
        "# attach surgery durations and LOS\n",
        "if {'subspec','subsubsp','surgery time(min)','LOS(DAYS)'} <= set(surg_los.columns):\n",
        "    surg_los['subsubsp'] = pd.to_numeric(surg_los['subsubsp'], errors='coerce').fillna(0).astype(int)\n",
        "    for (ss, sss), dq in surg_queues.items():\n",
        "        match = surg_los[(surg_los['subspec']==ss) & (surg_los['subsubsp']==sss)]\n",
        "        if len(match):\n",
        "            tmin = float(match.iloc[0]['surgery time(min)'])\n",
        "            losd = float(match.iloc[0]['LOS(DAYS)'])\n",
        "            for p in dq:\n",
        "                p['surgery_time_h'] = tmin / 60.0\n",
        "                p['LOS_days'] = losd\n",
        "\n",
        "# ward initial\n",
        "in_ward['subspec'] = pd.to_numeric(in_ward['subspec'], errors='coerce').fillna(1).astype(int)\n",
        "ward_patients = []\n",
        "for idx, r in in_ward.iterrows():\n",
        "    pid = r.get('patient_no', f\"w{idx}\")\n",
        "    ward_patients.append({\n",
        "        'patient_no': pid,\n",
        "        'subspec': int(r['subspec']),\n",
        "        'remaining_LOS_days': int(r.get('remaining LOS', 0)),\n",
        "        'surgeon': None,  # Unknown for initial patients\n",
        "        'admission_week': 0\n",
        "    })\n",
        "\n",
        "# ---------- SIMULATION STATE & METRICS ----------\n",
        "patient_events = []\n",
        "weekly_metrics = []\n",
        "spec_used_hours = defaultdict(float)\n",
        "spec_capacity_remaining = dict(spec_week_task_subspec_hours)\n",
        "\n",
        "# Continuity and lateness counters\n",
        "opd_wait_records = []\n",
        "surg_wait_records = []\n",
        "opd_served_count = 0\n",
        "opd_late_count = 0\n",
        "surg_done_count = 0\n",
        "surg_late_count = 0\n",
        "surg_with_opd_count = 0\n",
        "surg_pref_surgeon_count = 0\n",
        "ward_assigned_count = 0  # Now counts total VISITS, not patients\n",
        "ward_same_as_surgeon_count = 0  # Now counts VISITS by surgeon\n",
        "\n",
        "# Map patient_no -> OPD specialist\n",
        "patient_opd_spec = {}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RUNNING SIMULATION WITH EXPLICIT ASSUMPTIONS\")\n",
        "print(\"=\"*70)\n",
        "# ---------- SIMULATION LOOP ----------\n",
        "for week in range(WEEKS):\n",
        "    if week % 10 == 0:\n",
        "        print(f\"Processing week {week}...\")\n",
        "\n",
        "    # snapshot local capacities for this week\n",
        "    local_cap = defaultdict(float)\n",
        "    for (w,s,t,subs), h in list(spec_capacity_remaining.items()):\n",
        "        if w == week and h > 0:\n",
        "            local_cap[(s,t,subs)] += h\n",
        "\n",
        "    opd_served_this_week = 0\n",
        "    surg_served_this_week = 0\n",
        "\n",
        "    # === OPD SCHEDULING (FIFO) ===\n",
        "    for subspec, dq in list(opd_queues.items()):\n",
        "        while dq:\n",
        "            patient = dq[0]\n",
        "            need_h = float(patient['timeod_h'])\n",
        "            assigned_spec = None\n",
        "\n",
        "            # prefer specialist with specific subspec OPD hours\n",
        "            for spec in specs_hired:\n",
        "                if local_cap[(spec,'OPD',subspec)] >= need_h - 1e-9:\n",
        "                    assigned_spec = spec\n",
        "                    local_cap[(spec,'OPD',subspec)] -= need_h\n",
        "                    spec_used_hours[(week,spec,'OPD')] += need_h\n",
        "                    break\n",
        "\n",
        "            # else use generic OPD hours\n",
        "            if assigned_spec is None:\n",
        "                for spec in specs_hired:\n",
        "                    if local_cap[(spec,'OPD',None)] >= need_h - 1e-9:\n",
        "                        assigned_spec = spec\n",
        "                        local_cap[(spec,'OPD',None)] -= need_h\n",
        "                        spec_used_hours[(week,spec,'OPD')] += need_h\n",
        "                        break\n",
        "\n",
        "            if assigned_spec is None:\n",
        "                break  # No capacity, stop processing this queue\n",
        "\n",
        "            # Schedule patient\n",
        "            dq.popleft()\n",
        "            opd_served_this_week += 1\n",
        "            wait_w = week - int(patient['arrival_week'])\n",
        "            opd_wait_records.append(wait_w)\n",
        "\n",
        "            patient_events.append({\n",
        "                'week': week,\n",
        "                'event': 'OPD_done',\n",
        "                'patient_no': patient['patient_no'],\n",
        "                'assigned_spec': assigned_spec,\n",
        "                'subspec': subspec,\n",
        "                'wait_weeks': wait_w\n",
        "            })\n",
        "\n",
        "            # Record OPD specialist for continuity\n",
        "            patient_opd_spec[patient['patient_no']] = assigned_spec\n",
        "\n",
        "            opd_served_count += 1\n",
        "            if wait_w > 4:\n",
        "                opd_late_count += 1\n",
        "\n",
        "    # === SURGERY SCHEDULING (FIXED - proper queue management) ===\n",
        "    # Build flat list of all surgical candidates\n",
        "    surgical_candidates = []\n",
        "    for (subspec, subsub), dq in surg_queues.items():\n",
        "        for entry in dq:\n",
        "            pid = entry['patient_no']\n",
        "            surgical_candidates.append({\n",
        "                'patient_no': pid,\n",
        "                'due_week': int(entry['due_week']),\n",
        "                'subspec': subspec,\n",
        "                'subsub': subsub,\n",
        "                'surgery_time_h': entry.get('surgery_time_h', 1.0),\n",
        "                'LOS_days': entry.get('LOS_days', 1.0),\n",
        "                'had_opd': pid in patient_opd_spec\n",
        "            })\n",
        "\n",
        "    # Sort by due week, then OPD status, then patient ID\n",
        "    surgical_candidates.sort(key=lambda x: (x['due_week'], 0 if x['had_opd'] else 1, x['patient_no']))\n",
        "\n",
        "    # Track which patients we schedule this week\n",
        "    scheduled_patients = set()\n",
        "\n",
        "    for cand in surgical_candidates:\n",
        "        pid = cand['patient_no']\n",
        "\n",
        "        # Skip if already scheduled this week\n",
        "        if pid in scheduled_patients:\n",
        "            continue\n",
        "\n",
        "        dur = float(cand['surgery_time_h'])\n",
        "        due_w = int(cand['due_week'])\n",
        "        subspec = cand['subspec']\n",
        "        LOS_days = cand['LOS_days']\n",
        "        assigned_surgeon = None\n",
        "\n",
        "        # Prefer OPD specialist if available\n",
        "        opd_spec = patient_opd_spec.get(pid)\n",
        "        if opd_spec:\n",
        "            if local_cap[(opd_spec,'OR',subspec)] >= dur - 1e-9:\n",
        "                assigned_surgeon = opd_spec\n",
        "                local_cap[(opd_spec,'OR',subspec)] -= dur\n",
        "                spec_used_hours[(week,opd_spec,'OR')] += dur\n",
        "            elif local_cap[(opd_spec,'OR',None)] >= dur - 1e-9:\n",
        "                assigned_surgeon = opd_spec\n",
        "                local_cap[(opd_spec,'OR',None)] -= dur\n",
        "                spec_used_hours[(week,opd_spec,'OR')] += dur\n",
        "\n",
        "        # If not assigned, find any specialist with specific OR hours\n",
        "        if assigned_surgeon is None:\n",
        "            for spec in specs_hired:\n",
        "                if local_cap[(spec,'OR',subspec)] >= dur - 1e-9:\n",
        "                    assigned_surgeon = spec\n",
        "                    local_cap[(spec,'OR',subspec)] -= dur\n",
        "                    spec_used_hours[(week,spec,'OR')] += dur\n",
        "                    break\n",
        "\n",
        "        # Try generic OR hours\n",
        "        if assigned_surgeon is None:\n",
        "            for spec in specs_hired:\n",
        "                if local_cap[(spec,'OR',None)] >= dur - 1e-9:\n",
        "                    assigned_surgeon = spec\n",
        "                    local_cap[(spec,'OR',None)] -= dur\n",
        "                    spec_used_hours[(week,spec,'OR')] += dur\n",
        "                    break\n",
        "\n",
        "        if assigned_surgeon is None:\n",
        "            continue  # No capacity, leave in queue\n",
        "\n",
        "        # Mark as scheduled\n",
        "        scheduled_patients.add(pid)\n",
        "        surg_served_this_week += 1\n",
        "\n",
        "        # Calculate wait\n",
        "        surg_wait = week - due_w\n",
        "        surg_wait_records.append(surg_wait)\n",
        "        surg_done_count += 1\n",
        "        if week > due_w:\n",
        "            surg_late_count += 1\n",
        "\n",
        "        # Continuity tracking\n",
        "        if pid in patient_opd_spec:\n",
        "            surg_with_opd_count += 1\n",
        "            if patient_opd_spec[pid] == assigned_surgeon:\n",
        "                surg_pref_surgeon_count += 1\n",
        "\n",
        "        # Add to ward patients\n",
        "        ward_patients.append({\n",
        "            'patient_no': pid,\n",
        "            'subspec': subspec,\n",
        "            'remaining_LOS_days': int(LOS_days),\n",
        "            'surgeon': assigned_surgeon,\n",
        "            'admission_week': week\n",
        "        })\n",
        "\n",
        "        patient_events.append({\n",
        "            'week': week,\n",
        "            'event': 'Surgery_done',\n",
        "            'patient_no': pid,\n",
        "            'assigned_surgeon': assigned_surgeon,\n",
        "            'subspec': subspec,\n",
        "            'surgery_time_h': dur,\n",
        "            'LOS_days': LOS_days,\n",
        "            'due_week': due_w,\n",
        "            'surg_wait_weeks': surg_wait\n",
        "        })\n",
        "\n",
        "    # AFTER scheduling: Remove scheduled patients from queues\n",
        "    for (subspec, subsub), dq in list(surg_queues.items()):\n",
        "        surg_queues[(subspec, subsub)] = deque([x for x in dq if x['patient_no'] not in scheduled_patients])\n",
        "\n",
        "    # === WARD VISITS (FIXED - daily visits each week) ===\n",
        "    new_ward = []\n",
        "\n",
        "    for patient in ward_patients:\n",
        "        # Calculate visits needed this week (max 5 working days)\n",
        "        days_this_week = min(5, patient['remaining_LOS_days'])\n",
        "\n",
        "        if days_this_week <= 0:\n",
        "            # Discharge at start of week\n",
        "            patient_events.append({\n",
        "                'week': week,\n",
        "                'event': 'Ward_discharge',\n",
        "                'patient_no': patient['patient_no'],\n",
        "                'subspec': patient.get('subspec')\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        visit_hours_needed = days_this_week * 0.25  # 15 min per day\n",
        "        subspec = patient['subspec']\n",
        "        surgeon = patient.get('surgeon')\n",
        "\n",
        "        assigned_ward_spec = None\n",
        "\n",
        "        # Priority 1: The surgeon who performed the operation\n",
        "        if surgeon:\n",
        "            if local_cap[(surgeon, 'Ward', subspec)] >= visit_hours_needed - 1e-9:\n",
        "                assigned_ward_spec = surgeon\n",
        "                local_cap[(surgeon, 'Ward', subspec)] -= visit_hours_needed\n",
        "                spec_used_hours[(week, surgeon, 'Ward')] += visit_hours_needed\n",
        "                ward_same_as_surgeon_count += days_this_week\n",
        "\n",
        "        # Priority 2: Any specialist with same subspecialism\n",
        "        if not assigned_ward_spec:\n",
        "            for spec in specs_hired:\n",
        "                if local_cap[(spec, 'Ward', subspec)] >= visit_hours_needed - 1e-9:\n",
        "                    assigned_ward_spec = spec\n",
        "                    local_cap[(spec, 'Ward', subspec)] -= visit_hours_needed\n",
        "                    spec_used_hours[(week, spec, 'Ward')] += visit_hours_needed\n",
        "                    break\n",
        "\n",
        "        # Priority 3: Any specialist with generic ward capacity\n",
        "        if not assigned_ward_spec:\n",
        "            for spec in specs_hired:\n",
        "                if local_cap[(spec, 'Ward', None)] >= visit_hours_needed - 1e-9:\n",
        "                    assigned_ward_spec = spec\n",
        "                    local_cap[(spec, 'Ward', None)] -= visit_hours_needed\n",
        "                    spec_used_hours[(week, spec, 'Ward')] += visit_hours_needed\n",
        "                    break\n",
        "\n",
        "        if assigned_ward_spec:\n",
        "            ward_assigned_count += days_this_week  # Count each visit\n",
        "\n",
        "            patient_events.append({\n",
        "                'week': week,\n",
        "                'event': 'Ward_visit',\n",
        "                'patient_no': patient['patient_no'],\n",
        "                'assigned_ward_spec': assigned_ward_spec,\n",
        "                'subspec': subspec,\n",
        "                'days_visited': days_this_week\n",
        "            })\n",
        "\n",
        "        # Decrement remaining LOS\n",
        "        patient['remaining_LOS_days'] -= 7\n",
        "\n",
        "        if patient['remaining_LOS_days'] > 0:\n",
        "            new_ward.append(patient)\n",
        "        else:\n",
        "            patient_events.append({\n",
        "                'week': week,\n",
        "                'event': 'Ward_discharge',\n",
        "                'patient_no': patient['patient_no'],\n",
        "                'subspec': subspec\n",
        "            })\n",
        "\n",
        "    ward_patients = new_ward\n",
        "\n",
        "    # Commit remaining capacity back\n",
        "    for (spec, task, subs), rem_h in list(local_cap.items()):\n",
        "        spec_capacity_remaining[(week, spec, task, subs)] = rem_h\n",
        "\n",
        "    # Weekly metrics\n",
        "    weekly_metrics.append({\n",
        "        'week': week,\n",
        "        'opd_served': opd_served_this_week,\n",
        "        'surg_served': surg_served_this_week,\n",
        "        'opd_queue': sum(len(q) for q in opd_queues.values()),\n",
        "        'surg_queue': sum(len(q) for q in surg_queues.values()),\n",
        "        'ward_census': len(ward_patients),\n",
        "        'opd_avg_wait_weeks': np.mean(opd_wait_records[-opd_served_this_week:]) if opd_served_this_week>0 else 0.0,\n",
        "        'surg_avg_wait_weeks': np.mean(surg_wait_records[-surg_served_this_week:]) if surg_served_this_week>0 else 0.0\n",
        "    })\n",
        "\n",
        "# ---------- CALCULATE FINAL METRICS ----------\n",
        "print(\"\\n✓ Simulation complete. Calculating metrics...\")\n",
        "\n",
        "opd_avg_wait_overall = np.mean(opd_wait_records) if len(opd_wait_records)>0 else 0.0\n",
        "surg_avg_wait_overall = np.mean(surg_wait_records) if len(surg_wait_records)>0 else 0.0\n",
        "\n",
        "opd_lateness_pct = (opd_late_count / max(opd_served_count,1)) * 100.0\n",
        "surg_lateness_pct = (surg_late_count / max(surg_done_count,1)) * 100.0\n",
        "\n",
        "pct_surgery_pref = (surg_pref_surgeon_count / max(surg_with_opd_count,1)) * 100.0\n",
        "pct_ward_same = (ward_same_as_surgeon_count / max(ward_assigned_count,1)) * 100.0\n",
        "\n",
        "# Utilization\n",
        "planned = defaultdict(float)\n",
        "used = defaultdict(float)\n",
        "for (w,s,t,subs), h in spec_week_task_subspec_hours.items():\n",
        "    planned[(s,t)] += h\n",
        "for (w,s,t), h in spec_used_hours.items():\n",
        "    used[(s,t)] += h\n",
        "\n",
        "util_rows = []\n",
        "spec_list = sorted(set([k[0] for k in planned.keys()] + [k[0] for k in used.keys()]))\n",
        "tasks_set = sorted(set([k[1] for k in planned.keys()] + [k[1] for k in used.keys()]))\n",
        "for spec in spec_list:\n",
        "    tot_plan = sum(planned[(spec,t)] for t in tasks_set if (spec,t) in planned)\n",
        "    tot_used = sum(used[(spec,t)] for t in tasks_set if (spec,t) in used)\n",
        "    util_pct = (tot_used / tot_plan * 100.0) if tot_plan>0 else 0.0\n",
        "    util_rows.append({\n",
        "        'specialist': spec,\n",
        "        'planned_hours': tot_plan,\n",
        "        'used_hours': tot_used,\n",
        "        'utilization_%': util_pct,\n",
        "        'idle_hours': tot_plan - tot_used\n",
        "    })\n",
        "util_df = pd.DataFrame(util_rows)\n",
        "\n",
        "# ---------- PRINT RESULTS ----------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SIMULATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n=== A) PATIENT SERVICE ===\")\n",
        "print(f\"OPD:\")\n",
        "print(f\"  • Total served: {opd_served_count}\")\n",
        "print(f\"  • Average waiting time: {opd_avg_wait_overall:.2f} weeks\")\n",
        "print(f\"  • Patients with wait >4 weeks: {opd_late_count} ({opd_lateness_pct:.1f}%)\")\n",
        "print(f\"  • Still in queue: {sum(len(q) for q in opd_queues.values())}\")\n",
        "\n",
        "print(f\"\\nSurgery:\")\n",
        "print(f\"  • Total performed: {surg_done_count}\")\n",
        "print(f\"  • Average timing (weeks from due date): {surg_avg_wait_overall:.2f}\")\n",
        "print(f\"  • Late surgeries (after due date): {surg_late_count} ({surg_lateness_pct:.1f}%)\")\n",
        "print(f\"  • Still in queue: {sum(len(q) for q in surg_queues.values())}\")\n",
        "\n",
        "print(f\"\\nWard:\")\n",
        "print(f\"  • Average census: {np.mean([w['ward_census'] for w in weekly_metrics]):.1f} patients\")\n",
        "print(f\"  • Peak census: {max([w['ward_census'] for w in weekly_metrics])}\")\n",
        "\n",
        "print(\"\\n=== B) CONTINUITY OF CARE ===\")\n",
        "print(f\"Surgeon-Patient Continuity:\")\n",
        "print(f\"  • Surgeries where patient had OPD: {surg_with_opd_count}/{surg_done_count}\")\n",
        "print(f\"  • Preferred surgeon performed surgery: {surg_pref_surgeon_count}/{surg_with_opd_count} ({pct_surgery_pref:.1f}%)\")\n",
        "print(f\"\\nWard Continuity:\")\n",
        "print(f\"  • Total ward visits: {ward_assigned_count}\")\n",
        "print(f\"  • Visits by surgeon: {ward_same_as_surgeon_count} ({pct_ward_same:.1f}%)\")\n",
        "\n",
        "print(\"\\n=== C) SYSTEM EFFICIENCY ===\")\n",
        "total_planned = util_df['planned_hours'].sum()\n",
        "total_used = util_df['used_hours'].sum()\n",
        "overall_util = (total_used / total_planned * 100.0) if total_planned>0 else 0.0\n",
        "print(f\"Overall Utilization: {overall_util:.1f}%\")\n",
        "print(f\"Total planned hours: {total_planned:.0f}h\")\n",
        "print(f\"Total used hours: {total_used:.0f}h\")\n",
        "print(f\"Total idle hours: {total_planned - total_used:.0f}h\")\n",
        "\n",
        "print(\"\\n--- Per-Specialist Utilization ---\")\n",
        "print(util_df.sort_values('utilization_%').to_string(index=False))\n",
        "\n",
        "# ---------- SAVE OUTPUTS ----------\n",
        "print(\"\\n💾 Saving outputs...\")\n",
        "\n",
        "weekly_df = pd.DataFrame(weekly_metrics)\n",
        "weekly_df.to_csv(\"PartE2_weekly_metrics_FIXED.csv\", index=False)\n",
        "util_df.to_csv(\"PartE2_specialist_utilization_FIXED.csv\", index=False)\n",
        "pd.DataFrame(patient_events).to_csv(\"PartE2_patient_events_FIXED.csv\", index=False)\n",
        "\n",
        "print(\"✓ Files saved:\")\n",
        "print(\"  - PartE2_weekly_metrics_FIXED.csv\")\n",
        "print(\"  - PartE2_specialist_utilization_FIXED.csv\")\n",
        "print(\"  - PartE2_patient_events_FIXED.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SIMULATION COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRnRWRwXhBVY",
        "outputId": "66c72d32-af55-49b3-aece-72a6cfd4d370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ E1 schedule uses weeks 0 to 51\n",
            "\n",
            "======================================================================\n",
            "RUNNING SIMULATION WITH EXPLICIT ASSUMPTIONS\n",
            "======================================================================\n",
            "Processing week 0...\n",
            "Processing week 10...\n",
            "Processing week 20...\n",
            "Processing week 30...\n",
            "Processing week 40...\n",
            "Processing week 50...\n",
            "\n",
            "✓ Simulation complete. Calculating metrics...\n",
            "\n",
            "======================================================================\n",
            "SIMULATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "=== A) PATIENT SERVICE ===\n",
            "OPD:\n",
            "  • Total served: 15416\n",
            "  • Average waiting time: 18.43 weeks\n",
            "  • Patients with wait >4 weeks: 13714 (89.0%)\n",
            "  • Still in queue: 2064\n",
            "\n",
            "Surgery:\n",
            "  • Total performed: 601\n",
            "  • Average timing (weeks from due date): 20.77\n",
            "  • Late surgeries (after due date): 588 (97.8%)\n",
            "  • Still in queue: 193\n",
            "\n",
            "Ward:\n",
            "  • Average census: 0.0 patients\n",
            "  • Peak census: 0\n",
            "\n",
            "=== B) CONTINUITY OF CARE ===\n",
            "Surgeon-Patient Continuity:\n",
            "  • Surgeries where patient had OPD: 0/601\n",
            "  • Preferred surgeon performed surgery: 0/0 (0.0%)\n",
            "\n",
            "Ward Continuity:\n",
            "  • Total ward visits: 514\n",
            "  • Visits by surgeon: 141 (27.4%)\n",
            "\n",
            "=== C) SYSTEM EFFICIENCY ===\n",
            "Overall Utilization: 39.8%\n",
            "Total planned hours: 8978h\n",
            "Total used hours: 3572h\n",
            "Total idle hours: 5406h\n",
            "\n",
            "--- Per-Specialist Utilization ---\n",
            "specialist  planned_hours  used_hours  utilization_%  idle_hours\n",
            "         2       2,102.98      646.60          30.75    1,456.38\n",
            "         3       2,045.10      656.23          32.09    1,388.87\n",
            "         1       1,804.66      645.68          35.78    1,158.98\n",
            "         4       1,525.18      730.27          47.88      794.91\n",
            "         0       1,500.04      893.58          59.57      606.46\n",
            "\n",
            "💾 Saving outputs...\n",
            "✓ Files saved:\n",
            "  - PartE2_weekly_metrics_FIXED.csv\n",
            "  - PartE2_specialist_utilization_FIXED.csv\n",
            "  - PartE2_patient_events_FIXED.csv\n",
            "\n",
            "======================================================================\n",
            "SIMULATION COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IUoTVEOF7ZYV"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
